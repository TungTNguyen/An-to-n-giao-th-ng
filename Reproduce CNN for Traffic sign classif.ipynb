{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dữ liệu và tiền xử lý như bài báo Ciresan et al (giải nhất 98.98% -> 99.15% -> 99.46%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: C:\\Users\\admin\\AppData\\Local\\Temp\\graphlab_server_1472725091.log.0\n",
      "INFO:graphlab.cython.cy_server:GraphLab Create v2.1 started. Logging: C:\\Users\\admin\\AppData\\Local\\Temp\\graphlab_server_1472725091.log.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to keira1412@gmail.com and will expire on September 21, 2016.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">path</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">image</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 48 Width: 48</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 48 Width: 48</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 48 Width: 48</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 48 Width: 48</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 48 Width: 48</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 48 Width: 48</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 48 Width: 48</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 48 Width: 48</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 48 Width: 48</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 48 Width: 48</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">26</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[39209 rows x 3 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tpath\tstr\n",
       "\timage\tImage\n",
       "\tlabel\tint\n",
       "\n",
       "Rows: 39209\n",
       "\n",
       "Data:\n",
       "+-------------------------------+----------------------+-------+\n",
       "|              path             |        image         | label |\n",
       "+-------------------------------+----------------------+-------+\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 48 Width: 48 |   18  |\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 48 Width: 48 |   8   |\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 48 Width: 48 |   24  |\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 48 Width: 48 |   15  |\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 48 Width: 48 |   9   |\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 48 Width: 48 |   5   |\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 48 Width: 48 |   38  |\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 48 Width: 48 |   6   |\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 48 Width: 48 |   10  |\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 48 Width: 48 |   26  |\n",
       "+-------------------------------+----------------------+-------+\n",
       "[39209 rows x 3 columns]\n",
       "Note: Only the head of the SFrame is printed.\n",
       "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphlab as gl\n",
    "ciresan_train = gl.SFrame('train_sframe/')\n",
    "ciresan_train['image'] = gl.image_analysis.resize(ciresan_train['image'], 48,48, channels = 1\n",
    "                                                 )#28 cho Lenet, 48 cho Idsia-net\n",
    "ciresan_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gl.canvas.set_target('ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$(\"head\").append($(\"<link/>\").attr({\n",
       "  rel:  \"stylesheet\",\n",
       "  type: \"text/css\",\n",
       "  href: \"//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.1.0/css/font-awesome.min.css\"\n",
       "}));\n",
       "$(\"head\").append($(\"<link/>\").attr({\n",
       "  rel:  \"stylesheet\",\n",
       "  type: \"text/css\",\n",
       "  href: \"https://static.turi.com/products/graphlab-create/2.1/canvas/css/canvas.css\"\n",
       "}));\n",
       "\n",
       "            (function(){\n",
       "\n",
       "                var e = null;\n",
       "                if (typeof element == 'undefined') {\n",
       "                    var scripts = document.getElementsByTagName('script');\n",
       "                    var thisScriptTag = scripts[scripts.length-1];\n",
       "                    var parentDiv = thisScriptTag.parentNode;\n",
       "                    e = document.createElement('div');\n",
       "                    parentDiv.appendChild(e);\n",
       "                } else {\n",
       "                    e = element[0];\n",
       "                }\n",
       "\n",
       "                if (typeof requirejs !== 'undefined') {\n",
       "                    // disable load timeout; ipython_app.js is large and can take a while to load.\n",
       "                    requirejs.config({waitSeconds: 0});\n",
       "                }\n",
       "\n",
       "                require(['https://static.turi.com/products/graphlab-create/2.1/canvas/js/ipython_app.js'], function(IPythonApp){\n",
       "                    var app = new IPythonApp();\n",
       "                    app.attachView('sarray','Images', {\"ipython\": true, \"rows\": [{\"format\": \"png\", \"value\": \"image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAAAAAByaaZbAAABQklEQVRIic3W3W7bMAwF4E+OHcdptqFA33dPvIsgTds0lrQLRr73gBkRdKEfUjrkIUWl32ZkrRUKO3RkChIdHarOytbfQCXTx2kHRsx8hlCixq339Tf8f4W+6FHoqEjE3EjhaxEtKFtACioKNbQT+yCyMPG9iGb/RNx6SOGb2txjTx+TiK9djGo7/xmZTo3fxIAjhTecuYUNpfVNbOh3DdLIHpnEu+bdHLtfAS5tkw8PLudYSLzyBxMTFxy4N4FnZLq2MBUheWIKF44MsTYzRATP2wQfDcURR/KS3QMvOC/Bt8kzEx4ZWn8csoutAOvOx3bPzHobOmPoleX1/gwbakt1J+5RlS5bQOrdAsjPYPrCr8jpiSs/cGaI0jJtF3wjF64B7hqsZq58xNr3M+f0qemNSxGKr4XMYSk9vcevZ/UNfwHFPl8zTcZaYQAAAABJRU5ErkJggg==\\n\", \"height\": 48, \"channels\": 1, \"width\": 48, \"type\": \"image\", \"id\": 716539328}, {\"format\": \"png\", \"value\": \"image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAAAAAByaaZbAAABdUlEQVRIib3WS2+cQBAE4G9g2IftxDn4Ein//9dZUbxZx+YxkMM0cXJcpDBCgkHQVU1XdZO+Ag0JZGiZWVhgRlzSuHHlVIM3HyA1fFpBaFhIfza3rdspZSleS4E8UTgwBsf6NZbK8naEtp5rjn+lWUGauLuudo+ki4ZWYY4yf+GRzIHBxJUrkyEK9r8pgblWQOLJE5kO3Bk4c+Snhvc9KCVYQqIPHPyi44UDxcjMiak+uAVh+dDDa6SVaNXatHR0nBWG3epA5kwmazlz4T12ObR73KkOYc2WE5+ZzYyrNJKy9qfOQN5HGjPJiSMLJVyc6MLOSxzNJoTbKQVozx2Y9UJA4Lo2sqRs8nQOd9ZMh3DrAA70ygo2K/R7JD1JZCOv3HN0AQMd2ScK9/C2k4EWSBI9mQffOP8TrM7PZ+80u1Eq0VjfuHhkWoXSGBl55ruZsr17FxKFHwbhjhO9npEXOsumKbqZUmIKJw7rbBE/GEvM4bIp6d+pxYuF3HRlPAAAAABJRU5ErkJggg==\\n\", \"height\": 48, \"channels\": 1, \"width\": 48, \"type\": \"image\", \"id\": 716539384}, {\"format\": \"png\", \"value\": \"image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAAAAAByaaZbAAACxUlEQVRIib3U3W4UZRgH8N/M7Ox2t1+0gLulpSAJ1lIDxAMNifHQE7k/rwRvwI+AoTEaLBTUFrV0d/u1bdmvmZ0ZT7yB2QPfG/i9+f+f5wkeZ770tWtiXWcGxl47tKDikW90vJOoue6qIxfmQiVfJYjULYsNHenqaEm0feU3Z9ZxbiRR09c39kV5IYwsWtI3MtFTN/bCoW9teOumBQfOpQ4syiX2ygtRX1dXaCRx06IndlT8rWVTZs2pJ1KJMxWFw/LCZGDoyLyGVbEfvVExdOJSzz0nPrdnW6aKQF5eyGpGRhYceW+EtrFQ1wsr3lj3zj2H/kEhkE7RQ13NexdSHX2/6Ni0ZccLVZ/4QU/DqguFiVAxRQ9LUtsaKmK7dsxZ1dTT9kpsRqar6dB7oWiKlMp/qXpN07LAjAOnmLeqpe9A4Y07quY1LUsMpLLyQr3hilAgNdSRuueWsZuOnLp0aV7VolmBAJPywujUuqrcxI6uOzacq8vcN/S9c00tC+7aF8uNpxAKgUzotV0NNxwKXPPKDQ8NPLOv6o4HnjsxnqaHOJfjzK7crBV/aYjE9lz3kQu/qnvk3BVnTDN8MxRyFzpG7lvV9pPHnltXNW9dx56nbqshEpQX8kCqYtexNR8LzIlFNrW9tqWpZeKpVAeheIozk8n84aXYirqKmgkaFu1b0rLh2Mjv5sWGKv/DAqWZnj9lYmtqmBEo3BZ5qe2qu3q+Q2hBb5riJoVLB4Y+tSZXURUY+dA7I325zJaenwVWDL0tLyS81XbD5n8B1ERGhra8NJDLBR7o2xFpGkyR0ti+mqY5sYnCvlBiIlIVixRibDjREVgsL9RGMrElsyYCqQ3HUmOzPkDbitSynhWXjl0tL7T2jH3moVwkE0psqgqcuSUxti2SmLhQCA3LCyfHAgNPxQYSqUQqlUoUchQgVwgMXS8t/AtzvyvAKyx/GgAAAABJRU5ErkJggg==\\n\", \"height\": 48, \"channels\": 1, \"width\": 48, \"type\": \"image\", \"id\": 716539440}, {\"format\": \"png\", \"value\": \"image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAAAAAByaaZbAAADeElEQVRIiZ3VzZIctxEE4K8K6J7ZXUoiFXYofJLf/8FshcOWglzuz0wDKB9mpDuJKwJVmZVZifi1i277oiYpU05jmjJEs1glg0ea0Rt1OLqjrOWcopE2QZSYgiKuesg+E2LKTaU4eUwZQjCW1zdeBBGqVPrG05WVjhLptNtPVnm5WEaIB+dm8tbEomRX5qBrJ4/d/u5teL6XqzfZPf7s9UUOhZ5LNLqnDzJ9/moewp0pVb4Mj83WCPHtHC4pS3/0xPzseVnUbZCEGuqr40E1a9GT4ulBX56/WEs2+6brh+NwlOKSTktbqkfZdo8n+exlqd3+0ccnjzIcw7//43LlTT1ZvkeHKOcnT90fLxYfzj59su2WFXr69eTzs+d07fY0e3ans4cXr4f56MeP/t5k3cYam/UPDztf1UVsosfmtLteXA9PTz7+jbQIUWqa4eMweGawf4eXmnMab47u9KNPzVaSACWLn9XhcqjN6Nlk9/zK5sMPWioiTZO8uXr5+OItvA+9t5M2jKnOHs72Jae1UEsR3ZHmD67/FUv1DycxXIZ+dtpdm+O2KdYN9FBLdPvuWnw76VlMB73ZQi+z/nLeancr5m7fxdD61oyhODc9rHY36hBllQi5ZNqbLKuPqzxUsdlR2pRTqKJZpcJoojPlt3NYZRwqbLsKtWSahSimLLBEyLPZxyGLckxFBMuECDFV3Ddc8GbrY7tdCyqgSiwph0hx63ClOFvfocOhFxxDhBwytBTmDeBt6U/epzXsfQ6zRBjLEY4wKaYK+VeCHNa0UvbFShnmxZi2JZYKi1ShqLCm67S66EGlaObh9QeR1nALub/CL3j3fr0b/1tJx2RpzfXV44ufiiZI8effs9J1Oa63B6bLSTT55vLq9HiXKlWpG6phvLhMkbdcei8P5PJH+XBxWsZdyjvg5fnV29Db9yTfYr1roQ3zD6dfjNNtnLGskFP97suLt24r0S2Wo9uGI/02/TL11NQSzOnzZ8+votFc+03JEfqmrvxm/ej84BC0i/HZl1evKUIexnfo0GCwpb5M/vU/jz/5pKUvb74+ux6S7GYZ8c80Bmk7mcOY90pNI4Z5256uTXM6+lwQ5VjO/d4tyjDiZiVC34zhWN8TZLW4za+sk9zFuGf3rXfK1K5qqrg9qD9/2cuyl8fDZfd6B7OnTJere67+H8iH+FcTCzdTAAAAAElFTkSuQmCC\\n\", \"height\": 48, \"channels\": 1, \"width\": 48, \"type\": \"image\", \"id\": 716539496}, {\"format\": \"png\", \"value\": \"image/png;base64,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\\n\", \"height\": 48, \"channels\": 1, \"width\": 48, \"type\": \"image\", \"id\": 716539552}, {\"format\": \"png\", \"value\": \"image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAAAAAByaaZbAAACOUlEQVRIiZ3WQXLjNhCF4Q8AQUkZe6qmprzJMXL/q+QA3mVkyZZIAJ0FmclaIrcs/OzXr18j/UVCEqiK6iIMIUwm4Q9v3rx79937lMf+eZIVd0PXBQqSg5Phb1ffvRrZg8/UipAwDIvYGQMUxYuDK6qzyZ+PE8r/JZO1/f8zO/eX1bddkIt/HidECG0nBGZFlg3dahU+rE4ohvVxQtp0T5gl1eTgaFJ1nF2sbhom2fI44fSJIkmKanZ0VFVJwouzDxefQhKmxwnCJDApQlFlVRcWIauOGNbNkI8TcnUzSXs3VlfVyVG3uPkyqcJBsZrMjxPWVZElQzHpmsXVwWw26+66pAoTz3S6DcnmfCbfNE0YuqR48ar40CVJ1x4ndOzuTMIXquoqDNVdEY6usjC2QXmMMAhDlpGddeHouM/IptCyqzieqQHJMGxuOrlrboZZZ3fVNo9DSI8TptidPmTJD3d3HV23CpMshK6IZ5Jv7rZ3O/Niy41PTbe6O+wuDsN4poaRfUmGpGkIyUmVnYVhccCqCJ6pIbP18yBUiyG7+ak74NOiCdXQNOWJ5FsEGo5mP3bd7dn33d3d3aJrkvzEPDTJwLr79VVWDXShGZq7xSLLzyRfCtsG6i6qLzdv/M6P5uZm0SRMz6gUW5e3ybhZffmlehW6rll3p27J8oSXEGLf+kfdsLg5++9KURTZtkPGMzW0bTtvrKoYurbvjJCFLEsy2jO51IZklnRFF4pZ7BegJBkOv3O9Wf8FhfMr76db6lYAAAAASUVORK5CYII=\\n\", \"height\": 48, \"channels\": 1, \"width\": 48, \"type\": \"image\", \"id\": 716539608}, {\"format\": \"png\", \"value\": \"image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAAAAAByaaZbAAAByElEQVRIiaXV25LTMBAE0CNZDtlQe2Ph/7+QYgkBEl8kHqSYZd8iVOWquOxMz/R0t8OTIFBEokwRIANBvQWxXTedtP2jtIKUehM3mNJeyUIHQq4ztEp5QwpbXXVGdbzbEd6ykGuhkdVBYvbrL0jFvR0heMd0MnCwFzi4Y3ZhuhJ4M0J4/qf4jrGyX2SSsUF+d4a1a4ZG/MBoZJYrX5HFRLTnUeJnF0tFk+SO5MwqVE0Wdd2r3xR39dfNCH1DRwYj0UdGr9vTshnoDPedQ4e6nYWdO54Ujt45igvJoWuGYCDIrHVxXxh8u07xRpqTD50Giq3W6sSDxKPZj+1RaN7KPfJO1XhV0tmpVY1eDBxFPps4WljlToSlyayInASeRI9kZ0YHTjB0IRQMWwSDI8GLyGMVQSZWP6X/DLJwzWFHoweSe0bn1kGqQLednpbWa3C+EXT0KvBJYV/do18audJ2PYMDhyr1XLMiUBRSdy4V1tp+YXVh77lGw0KoH4lINHWGwMz+iqGY+GpxaZMlk6q6uQchPIgCO/dkE81MYcuwYt+onJ079xCYXPhYERrtV+MONBYv5i4Ete8Ti31rfq37DVJjaTax9Gz6D7k0phkvBmIkAAAAAElFTkSuQmCC\\n\", \"height\": 48, \"channels\": 1, \"width\": 48, \"type\": \"image\", \"id\": 716539664}, {\"format\": \"png\", \"value\": \"image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAAAAAByaaZbAAAD7klEQVRIiZ2V2W4jSQ5Fz2VEZmqx5d0uubsH6P//qAFmgHG5u12SrCUzlRHkPLh+oMQ3PpDgIXEv9RSGmXCHSJnqE+ScSO5MKcBywQ1kopAFIEdyFAWZCXkFhGFODZHyRIQhN34xcoSgBFki44Rao20rNSeGyYOUhFyEVSBbBC4jENEIzZcn/vyY43nH728q7AkckBtVegZAYMBjx+m2wKy7Z3cecQTbseIOZk7w6wxyMIdQ4mYF8XQ98OrGczj6a5PxcqD2QgEWOdDXRHbHXSte1qmlGhAZ/eux5zMWVI0ApCnr5/xpdUu3XPDiOlMT2NhipduQYsSWxlgril9nqAYKsbq54uZqSZgnCMOSIb6/UUgUOqazCMsRhmLF7eqGq4Vhxb9WXKyS/34fqGrQNJHbAmQj0N0Ns+6KBcFYTLjALPO/9x1IkKOSLmSwELkBdTMKW36U6ZbH2YwSb/zncBDqZjRdxb3g5BAkMo/rAu//EB5/U+9EevsvxwOBBqNbL/m3T/SRRdDNF9yHOH20zNv2k03MOb4N9F2uDKmwei4sxxnncoEeyMy6ORGVPXNub8eOw+GdY39k1kSL+zN33nJ1dEwZa8inFwjHcFYxP5D33zlPQVGb6NqRKYLVzmlqRkbzsAREFeweT8b+uCCdHRolXv2Im8iznnyJHpTgOGehzGo38M/oG/YWRAhZvuPlPSGJnIT9LEgPJHOuU8+wP/V489VOWq/ZSl9ZCjJmYRZst1ZhZ22b4hxRRncPs+bxRZojERAe4RcwhJyYzSmaOJxb1NQjtUyYEt/WCI+KIhAN8hypMu3ndDZRpko+k8jnCbOO5blx6Ha4hKbCFDmlQnMGtxPlDBAJEO1K2HUEfQ81xG6slEsYSnBqj9xwzWastKRKNC2rxx173fc0bdBRqNlBuUZiaE/0sy1THfB8FpH+4LcfibqdGj73D8zl7DcnBrJ5UIB+2tKTGUcy9vpKem74Ph3Ar2fkvOWjDFxyBw9Rh8SUC7U15Knht7VIcU/Zl8Jq2dHsjrT9RFVG4J8TcxIok729YZ0zEcHTve+4pWHwkWEsRHwVWMEDkoR3z0+YgRA08YT7Gd98sD8EXKQHx6JQ0kTNGbt/SCSgRsI8IA8Dm48Tn16R5YRItdIvoFrldU3gBOaFZIhtfLA5HQhAZCIocsZYoIDFeQbhjsxQ1Z7PQ8/pWHBE6BJfMsyFD5DzjM+/Vo9YFqrB+82Pd+bxyalWRBBFrwERgoCUrnjoPZGfC+0w4y3c0fkH8VPWEfqmIGSYA2aktLyneIAZh9n+SC0BEo4u+Q/6ZsIs0/iXFYEMSw0RTtQqjABLNMNA4f9D4UGjS1cz2AAAAABJRU5ErkJggg==\\n\", \"height\": 48, \"channels\": 1, \"width\": 48, \"type\": \"image\", \"id\": 716539720}, {\"format\": \"png\", \"value\": \"image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAAAAAByaaZbAAADfklEQVRIiZ3VyXIcuREA0Ielqqu4NqllNDFjOWYcMYc5+P9/xDcfbcm0aFJks7eqAuBD6wdIHIADIhIvMjKR4f2FmNWD3GnU2TzRBKmTi5LkpItC5tyU21FPDqbmvIlZypYoSEkc1SL3RI3S20evXOE9XS9P5uCi1zUXl7oOJvPBYVEWBU0j5BApQtWSZbRO+oOHokpNv3KR7XeWplKa+nrSpwytOo/e3XjeaHDaQ5JWhiZs7IOwE3KrUlNGl72zRy+RKFZBq1pRJ8eVOChHUxFfTcq1WTg/1w0e92LT927WOm3jZWNbHCdD1s1KVXONDIak39qthJ/9cuavRbJUz1v/+WK/EUij8qK9nqQYV8bO896Y/e03lxdaEPTNhyu3l/6dPTRjcFZssygOVkf7c6vP/uiNsxpFLShJ/ix3woNwJo6mN5Ci4cx0kLLffrca1SA2RWg0q8nH2XJwSPqoz7JVsQT5xvtF2GpF62QpEtQsfzK9qJOcpNeTQi8y8/HG9F8PT2pxceVP615sYjFy+2h7UKI+C1KzDPJgOfralOh47smqV4JKGeRL+y9K4E1Zao3OeGbZsVDF5ZSfYVGD+OLqUYwqMYcmIBqSkIQArWK78rK1LLqVrpOj1oTXkyI1kEjaKTyhmhyeTStDVY8sOoS3vFBPUQvEqCFSHT0O2mQ3/0jKHDTkPjg5ZkTr/8nB9WK2+eKuqcRPfrq0zNKbSFOnRRbL3pjcLv7+Dx+Lom/Od0IzzL5n+2oVlFyKRp5t1gTT4J+Dx+An9VfdlYuD40Z4cgx4w8+X60zTFZsHt+/42Xrr+VxzcRRvhGQz+lYVumDObXE4oznsvPvgLyshWIog1B9B3x2FZ9vR6mB5PalVx2yMNs/uOp9nXRWbRtSihfsn31/0nbrYZRwHpbN6EgO/aFkJJ1Kr4r2Hf/mapF7d2r2hp4u61UdD9si88evKWZMsxRLc3bn/JgVj53GvhusqRtdrif2k673/YH2jk598/+ru4JCkteHB01Z5/chaNzVJ126rONklMUlJVqpp1pocXV17+OawF3JDFV+ka3mQn4T51NmharS1dmH46mmypLeQrk9HJw3Ozl0d7BfTj9vV3vWlwP2duULLpxlUm3a07JQbV73DZLGMxizfu9/bFe1UXa8nXZ36YiVnKYhJHp2NBrXZ7+z3Co1SLYv6f7hlvSNwuwN/AAAAAElFTkSuQmCC\\n\", \"height\": 48, \"channels\": 1, \"width\": 48, \"type\": \"image\", \"id\": 716539776}, {\"format\": \"png\", \"value\": \"image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAAAAAByaaZbAAACfklEQVRIiZ3VyW5kNRiG4cdDTZ2hkzSiA0Is2HH/l4MQsGDqlmjRqaSqzrH9szj0BeR4ZUuWXtnf8KcfKSKQhizPusi6UIekjWXHphhaTUnYZJO2VZ0vqjrb6dIQSjEMQmRDyl65aqpCbdhXs5Qk83DxxkxWh4tESEPi9YQRqj4kvRkiKXZHZ8UhCTbCnA0jizWEQpfjC6FU1akpLvIOeZZtKZCUlYQ2FGNoctVc7t375Kk4mIqmQdTlIa8lRBZ61hc5Jc32K3eaqX0ReQxJhCpeT9CQki4P5IRd9eDkOAm16DohxjodcjYxhB4Odi+ab259kLz94Owqif/hockrdGiC0Jfzy8Wjhz/85FvfZ7/ZXKumhNGlNTrMQxLDIKmi2jk8u/fZ1ZUXH6k282LkscZLLQsjMPaqc3Xv6mufheuL98rfruz6kjhrfimlL4Q3exf9O3fGg2d3pr1bTwddKkKmaSsIHSkkXsxu3slilmVTuHU5OqnJMAr6itZgLNtN19wcVNHsnN1tdQ8nv5je4JxZ49awhGpjQ3a7R70W/rHtSI8ufj3bG5OxqvmSTLV1PvrB+2Ros8+e/P6IMnzr+S/DrptWZZpscNJv3UCI5F/d0423WtU9zj7JVV2lQzXYGo7Xktxl89aNycONkJuD572hZ1uX1xP6kG23TsbOrTPN3NyYnX42613XJ7HMhxV5iGFrd3SUP/pTD8RAQFpuRbhy3sqmFb2UJS/DRj8Jt08ye0NRsrqELULYd+c1So8uHJIkF8E7yTR7UZapXIZQz+oS/HVz+qxX5KLpw9C7tliqyCEroUshr9FhJFnvKEXTiyIVRWh9adwksqTOkv4fr4td/aSY6CQAAAAASUVORK5CYII=\\n\", \"height\": 48, \"channels\": 1, \"width\": 48, \"type\": \"image\", \"id\": 716539832}, {\"format\": \"png\", \"value\": \"image/png;base64,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\\n\", \"height\": 48, \"channels\": 1, \"width\": 48, \"type\": \"image\", \"id\": 716539888}, {\"format\": \"png\", \"value\": \"image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAAAAAByaaZbAAACtklEQVRIiZ3WzW5TRxQA4G/m3hvsOCYm5I+ENCoJCqq6oYv2KXjqLsqiK4qKKmhLaVEILmlsx07ie+9MF4EHsM9ypJlPc87onAnH1KIgZ1kShOw2sqISFCrrfbtqHXeiBaMMxNuDCaJM8MX4vFZ41tXTyi4XF4qkECUKjYyYhc9YCoJG9PwEwcjFEkKQBVlOsizKWWHggdKrQitpnQV9Y+dmiwuxFiWRLGtvsxQMfOOdlQalaHQhyxrt4kLKCCiS2u2F3HXfuRVbp6JCoW0lSVItLiglBLlQaSWhYwtjwYPkI4JiRRbMlhHaWiFAUmkEoWugRa2348pUVgRRY0W9RJai202JFkHcsyYJrsyCDcENrXbZOpQNyEIWBcH2vpm572Snp7K7LiSCdrk6FFHWIpNEXQ8/qT3xxMh5dE9hahpEKyqWeksJSZEEUU/nwolHggeGpxp9M+OuqR3DZe6QCoW5IGVBYV+16q47OmonYy+VdoxLu/pK54sLq1ktf+lEB/aN12x47A9v9R6Zei0YjFTOTFwvLvSSS6UbkYcO/OfmWPDcBz22fG3iUkjemAnL1KGXXGqVYqknmjra8puPGt/7atPUnr/cuzKRJeUSWfqEVXNlx0Cj72DTe7WhKzuNXXPv1IeSvxXC4sJori9JVvYMTKw72PCj2r7d2+59ZOinxrapsbi4sH1tbqqyfuhc48ThKxd6NlwoWq2ZE2evZXuiyeLC7MaVqHJvYuQH3zr/00NjXSNvr7ww9NTx2L8avWVm3OWNG32lSW3DkcqHPZufG97vv3jpwBv5vrGuuWKJSl/riyqdgW33Veozj7X+kfz8q9J7lbVjp65tLvMTGBQuFValuUcODK091TG05sLhsUoU7O4ZeaH2eGEhPJugr9IcOVQhtRImpnKj1chS15nGdIn58D/QCihYuCd9OAAAAABJRU5ErkJggg==\\n\", \"height\": 48, \"channels\": 1, \"width\": 48, \"type\": \"image\", \"id\": 716539944}, {\"format\": \"png\", \"value\": \"image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAAAAAByaaZbAAAFT0lEQVRIiZ2VSW9cxxWFv1tVb2h2N0eRFNGkyKbsBi1TEknJsmTZkJxA8CYJ4CBwkEWW2Rj5C/kN+QdBgGQZIAliw1ACIVEcDRlk05E4WCIlkeLUHJrNZrOn915VFrIJWciGPsuLOqfOuRdVV5yNeTrrQfsZl7lHq3mwQmNi5UuWE3mV4RXzY06CsygBwOAWeFq5UuP2XGQVmP0SfaVyTFhS85R6umsAovkKBn0fu9/dyeT68naa4MrYrygN95zHOBKisuvhG1AcEQYmuO2nLXPpg9Eml8Z2z9OeqexQLmuPwUIYEHkvEpwUqM8sj9BMjbfXyGx4ltvpW68zF4rweaBPkh/ok0OC/PWVTR7uDBS43ulPddKozM0TJUqhjQgOa/GDS5cPGfLxToVaI52l3nqjsMbSxprCiSg0FkSJA+2mxmnPfsvQ67UadSmVYHLkySw7ZSyCH5BKt1rU607wJPnHHuMDXQCmWKsS+tLg3OTjL6vsm9YFti+/DghAca3GDeO8L6CWGwCMzdY5IJPj9OpsuYpyE6fp7zh00N8P6ZtRophuuA7aMOU2RRK1v8L2Yr2Swl27pJBv2p5wC5vr+As9OUKl323Fttk11K2LWxvG2u9e1vLSeRjIRkl2T5b9jbw+epecaLxUzqOy6ss13vm/CieSfdy6f5fcWRPWWoSDvfMs6GT8DXTLObRJEjwFxDEOz5CH6xrhbs5070Ucz5eeEcRnCz7Rr38XoKwD84tzEP32Y0P8wQcmz7lPcBxb1+ejVDCYL65EMZ1TWR0/HOodHM4Hdc9PTdWiP32SG8vFf+a0Iuc9dlI0Rw+91ZHhWFCuoRnrhSR7/UPegp9Tf9vd4aMP34HWLz+6OgpeWEMWTahiuqKyQ1InAG/o/ddoBre66C8k92Ec2Pve7PwoDHsOIpOqacLYKqStDfCmJhM8bJULYh3OAJmtNh/oS5WRpmk0PbwkEiRIA4gokrgScQYixAfQiQCkHSJHD90iwkUWCA+L8b/+8BNOIQ6lASKrAJwjUcaZEL8ZO1z9kJDcD/oRcCgDkDgNoGO0M9VMSFMU2Ib92l+8FPQDYr96wYkVgAMLYqTVpJmxMV7Dfn3DneIPugEXgxNQz2k7dYXzjxxaGWm1dsLhJKH59Hnp7t2ZwlURcJ6n9gEp2TSwWdNae8qqVmu91RDBLrQAbBiuD2dEgDA8WK/A0mYQAo/qzkmvyZbaqDZziziKBx5C9HfWfuYDuHN8+sd3y7i5sB/uzQOZflM9CFiemcqx7p58dhUNM7x98vmM3uSnv/mnwQt+2LPF0wMLqcGjT/ogY0m2Gzl2a/ZmG5dwP2L4uYzWvD9yOyB7IV9+zFbDWPLHjbN1vJWtXoxL3A3kYnjtRcHJSYDK7kMWlB1lJKPH4ihu7WVPheGqij23rHO8/JGxvTr9WdFPTpw6lsnpM17DVe2z8NnF1BPr4nhRn3iZsPrg0X8E253v0Nkeg5fgGuYWx6dqdwKE60VO9b6wcj7nb/U9L2Kgp7HDwLfYD2FbSJyomL/EV8IbeB7T3EtefY2h440Giw9293GI66PXucecrJhdm6IeuYi9m6m3FJ+qWKFlaQVBBBLrcJLkh6hWnlX4t9IT9UZLJdrgNWeT94Y71gaKcWJx1pFEcRQ7wE5NRKa8uhkqKRoXKCrGb6PZUL+PePO9MsyNLHnEosBmKr20F0YfPKJUrXeykT1yaPl+wyDOD0niSCn6+r9zkeXp/S84Oy2WybXx0+xt/3cGVLBhMBm51opISRASqbo2KPELFHp7YqwSC6XtZdaSJHa09xX36Mr+DyA3ZQqnAY9jAAAAAElFTkSuQmCC\\n\", \"height\": 48, \"channels\": 1, \"width\": 48, \"type\": \"image\", \"id\": 716540000}, {\"format\": \"png\", \"value\": \"image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAAAAAByaaZbAAAEzUlEQVRIiZ2V2XJrtxFF126APJxJkZR0ZdlO8v+/lKokjuPKzR00UJwPeueBzgc4eO6uAnr1XtBTi7BHfU8GyKUhKzSZXq/ns3ASRbIdRunaRIOTkQ1EM5jcPrd+R+sxIoUIOUEVG2RIEmFbRrPV7t/zeb30RpJRmqiYDExmS2PAOMEM537T2345tbAp4QYthTJMWtUyiiKanVY3aUrt3pcSNmEklC7NgYVTYWyT6bS0mZ53UnyoCEW0Zhk5e1RTlgAcBgkUj5vPryH31LiqWQbkhjJUJhEOFD12YKTYbPdfA4i+1B0IobCxJQV/8ESRRVFaBBg0HOe7kUJ6u783AtktbTszSpQolhUYJNFN+yvop7FU+lEFEUK6YQsLJaBEIpDW08vF/uHnZ9xyMSgBmWkjsjnItOxSoshKHNsvX+TV3eB5Dfv5poAtGTnCKlM70+EEYUur8pUYLp5muu7aNdanY5Np1q0xEmFI27ZRt/iuKKPNwt1yXPTttCjOdIkbbiKwJAkwUunGA8Snp6Z+/azM83gQyCkLy0Q6kSxsEyrb8Q49/HDuj6fTD/fkcbQKASAwLlMQEgYVeHj6dmT+XA///MfHzPU/XLQ5ni371kWZmtuNRKDtZv9No9W6/f1vp285H3x2OQ3qqVc4EkmK2wvCQmg45DVVN+Pvv5L65V8zZ+Zx0gUpSyqKEAJnWiqlmzSjT9v2vYTQK59MnsejICSbdMb/MgCirKanxvZJGvdp90ut5+j09WmJncLJbVtNgs1q/fJqHovK3VMqf1wxW1T0tr/rkAJLLjNxk0Bo+nB8geGfJ61GN+p/fFp2nb/2yuhO18SO4I/nod5kgYg6y/cww8XVLDU6/aV06Ydvvzgv8+UhyVDKZSJu6GK0bv0ZnpcK7b9f7dOgJvXjQl+2l4N/hztBtoTq42r3Fv7pOZLdvj/qkHUU4nRKHQaTQ5ONW0BaIWKzfnkNzRYDqkacXcrh7MrsvqT40Fhp2xEYgWO2fHsp6pazKuSPateyp8cPj6CrZwIiFAYFDGb51qx6NzdyzE740uaBnY935ny42yAiamAj1E17LB4+WbL6bm6zXtiY4bqTXndbFESWkYwGeljs92j98wBMVNXq1d0gArXOb2fRD3fNRiEj5Xb78gKL+2KHFY7Dx7talUnn3b1wfxkGpMtIROhPx+8wuLsfW2Rk++2v7SNPg5EjUQ6PR7du/JG6bRQaXN6IMtjOjcH526/5dvly2CVCpt51xMt6BnKoiDLosfWwNSoEOVqkxOvZatgxWg2FTstORBSVKOvTAT98agnpVO6+gpkm2UyorTZIx0EXEKqK1WYnT9dDLINUHh8xtXUEuF19fdjg/XihoMyJyeP+yPBuOUsTJjI8zP2a5ycsY7kV9pdrnZ97/z95KJO2w3W2dG3ZkHEd//zpMp04MERSSukOvGrOrsox6Xt7pM/15s4KoPFEV8ftu8p23exeVA5TR82ymrxexJcvSA4LCUFIIakUFEURbfZ+Gqzmp+rV+v2l/C5OWZYz0nbcJmZLNnKK68fio3LWW+GG1BG2ob9VYoQSITmx/D6YVUYs36MJ32QDtqybGUqKKM22hK04HWp+4WFbnUCmbdxnOp1O0uoTKmnL5OSU4/8Cv/AYxN1rS6QAAAAASUVORK5CYII=\\n\", \"height\": 48, \"channels\": 1, \"width\": 48, \"type\": \"image\", \"id\": 716540056}, {\"format\": \"png\", \"value\": \"image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAAAAAByaaZbAAAEbElEQVRIiS2WzW7d2BGEv+o+POTVteRxECDv/3hBFpl4LIkmT3dlodkXUIv61ffoJjt6tm1sQBYKS5FjPsZ9/XUi0sbKPUEV2CFJhvntoC0jI3H9+lynEhctkTM6DLCJULT0+ml1ywI56rpdIIVb2isfhQMrMlA7M2otDTUBNmd1W4JSgCq2AcaK1TKsW2WuzSYk+8KQZUhJcuZmScDEajymFlDPEm0aFHSqSVAo88CJQ8vGckdbonvrBlrKiGyjXiMhQ86W7C43NEdLQIMRGIcLsCVckXuUC4mwtcZwyRDWVhhwqnM4UFZlRk7xDDCSkJ+njwple8SSjWzaStPI7ZB13ylwCMWCU49ouLfAtmmpKdK2IfcRhhZgaXqJY99O1GNjQSglQ2s0qEMzpMaoQXMJTWIHbiIsRYwI5fDCVOTLY0dtI0s5bjRe0KwWzHbI3d0BrUbZ+c+3ESxLJHr5kHlLamqJvp6rR0dHGokYrIjDsgWKCCErhGBPAl1TPYyquw1VcozsKhTq9la29gEDfU+COzYrYw0m9GqFomveX+Lm3C6JCdgdm01XhkRUXIKIQOGuuzpE9pRN7IUAfxs214i1FBF7d2RIkY/+SyHkyjyNXieBA5K7oV6vAutuBSDH+uyOwBarkWRbEV19xACfUwgqhCTIWXYBxduHYD6tkO7//Mqx60adUXaTkiUyAlKsiHlJ6LDBgFbkvou6M5EDp5EcBVhR2hdYByA69n1zs2PVGAmCwrjzkRUua4wT9DpwANq3z593HV5wffOSkBQtD1fY4zYlWSmHgevPLn2k51XW534CQgblC27l8LcPYD/ezwzFf/8X5T9+6By5oNe3CsEivOUhS1LHQvHQzyvy15/rX+N0viSkCpxxd1jgCqG2PRe4D8zWp14JtCqfQ5uBSsmGsvIBo9m2E/TyiJe9eXtO8t39iI7eq6TKbFuklDPc4f1ueD6j//1+3b8zHe/pGILMZaiJFcKE20J5I+3qD+R9LAybrou22cBeU22Dg3JkNtIY+jyfEI+dhPl2v59WaW4OXT1oWwQoPQrzsunXMeXaB7K1bev995JiDvCdoTDOx9bll080fox87H3aOmv4/TH3o8/7iM7tbpzZjt7ycHhzka+HZqHzR67I4OOIjJwHwptuqKmy1oCMeaI4UHuZ3h5IC0n+GhX3/o58HdxNwJ2boSLuz2VnJTL+CpIE4HjF6hpjmzHw8Qk9vVbXQkjgawu3CLBQtwSF1hre1GXpsbDqY2baws9jNdVVVbb1Fan13TW6Xj+M9wTqlge/b5dpA+q0QQYw+vnyMdjKwKC4616XmlyEQMY0WNbfayQzFGXg/ODvGwAO2VF8wRBCX9YbpfFYN4huyaj1VT7YUsO2hhxJ3s2CvhmdZxiMMXLYalXIilDGtMrFqnLgVo/VGKwv/hHKmA19G3dZ2zV+O6JDDcOlf2R12BEKQSPsolFvpYYmaEjaJrv1No6gy3Q1llQIUvHbjmiiFeOUrOw2/j+BQ0RADixMvwAAAABJRU5ErkJggg==\\n\", \"height\": 48, \"channels\": 1, \"width\": 48, \"type\": \"image\", \"id\": 716540112}, {\"format\": \"png\", \"value\": \"image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAAAAAByaaZbAAAB1ElEQVRIib3Vy0qUARQH8N/MfJ/XcTS1SMsSQ40sh+hCERkRUbh2YYGraNm+Z2hf7+CqCISkyyZF8gY50gW6mt0mNEzH+zQt0gcYF995gfP7HzjnxNICAuI00UI7LaTs5i6LfOIr5ZSyLK7ICkIJNjlKLY2U8Jjv9nGM1/QyyATrKL5D8aQ8pDnNT8ZJMU2tAj284i1dBGR2FLp40rITnGOGDPOsEDLvKu10cY8OLpLkfhSkpBqyZFhknYACJ90El/nAQyq5wK8oSNXSTJAjR4wYpZwywwHydDPCC8qpioJU7zBfyBCCFAXmrZNnjUnKWGOU3mhIWZ4TkiBFNRsM+Esfy/SzySpttEZBKjFPBxl6aWWJfhqM0McqCX4TMLajKQVxdczSw3WWqaeCIYeIUUN8+9BVE48i9A/13GEvlSTBGc6K2bq6/z0xQuaiIb3hEZ1cY5b9DLPpCM0g3N6rRr5FQVowTQcPiFPKS4YJTHGLShLkSXOFwWhIK+zhOP2EW6/PomaWqKBAG52M8SyaBRqijG4O8pQ/LFIlyxiXuME7pphkIwpSqIYn1HGbkI9kyUoxRIEq3jNKjvUoSHG7WCDDHOdp4DMtmhhnhBwDJKkgX3yHf+vYgwMMDx+EAAAAAElFTkSuQmCC\\n\", \"height\": 48, \"channels\": 1, \"width\": 48, \"type\": \"image\", \"id\": 716540168}, {\"format\": \"png\", \"value\": \"image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAAAAAByaaZbAAAB/ElEQVRIib3WS24dNxCF4Y9k923dF2Q4QJBh5t6Llx0g2zAQjyw5iu6jXyQzoLQA9cC9gPqLp86p6vDV1c1sx6NHn/zB7Iu/PBtY/W4nkXzzzST64Nc9KSZ3GWY3/9D525PeQKfYG/nsVfaygfBsj+xOxE93siwrOjqj3xSim7u4gbCaUQQmL0aZioDC6rt/nZk8I32cEP4UdRaR2dRK93pJkVkV1cCgQ/g4YcujWUQLo05y4Ng6ExjdVReyvaTbQCgIipmoc3Z8lzXCUWcyM+IobyBUQVYgOTm48Oro3FRezaIHokmn30jo3Vu/J1c3dg6q2cisqM4UxbzFGltaYlHsOFisVg6yaDFx8uCHyGBUNskKVZUIqpuVxfBe7egqqQyCrG4iBFQ9wc3dwIvskypQHFyVd6tsIxQVM9nNZ3v+c3GSBbi0skHFtjm0vlLLyNrEH2W9hbuzSwt8q/4LrEHVia70FsHCVZVkPdGTLHvbQNsSxywpjHrZQnXWefDKRdZbydru3/aG0Ia3SA4Goqh6aFIXqxuzXrJFpSKourZ457ZAjlahWT7LRhM7vdX6qwYXZIlqFszcDEgmb03u6GR5y314c2uFJLRjN5oFtQWtHaTmj01XlPBejSC1mBWF9osRBWvLZXLaSKioGkQkShpQlZtvgmDv8eOE/wFTFfJGVmW1twAAAABJRU5ErkJggg==\\n\", \"height\": 48, \"channels\": 1, \"width\": 48, \"type\": \"image\", \"id\": 716540224}, {\"format\": \"png\", \"value\": \"image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAAAAAByaaZbAAADZElEQVRIiZ3WSXMb5xHG8d/7zgxmsHGRIFISWZIZ24mcSsWu8sXf/5iDc0sOliNHpjZSIkAQmAFn9SH5AmBf+/B/uvrpJfwtOHStnDq0UU5NHIkLxz5du7GSjWRSN61WkKTNVCsTo7Xg0czU3PGJ3MuVLy79t7FDsdPqDdGekbYjvUh04KmTpaUr/86l/tI49ZPnl1Y+Ssc2orA3IVy80CvFE8HC8pNGLe8lkpFgbjzgyodSKZWl/c7YsVku9d6y1RpUicHQG1TS3Ny57NrIRr9/0WEnMdd3NjZmg4WJ9Gu14cZrleWgl3u18Jvc5gGEkZnE8EVpYfHMiVQ2MjJ0Hnvr3UdBpXll4nfv0zSXiHb3Ljx3/MJWbdcqGcw9NZ56p7We+8bgbn9J6UShVJ156dyzOwP6WjAMEk8dHip8dFdKTSz2JxQTg53Hz516oYqCWj8IYtDJnBdGxn5diTIn6XwwiA4OFH725c7GxGhhLhuMjWQXEpVPa1MT2/0lJQwy87k7PyuXotZZZvB4JJPLOxduHaxU5v6+PyGjNTIf+yyxiTpBx1xMFcbSsS/mss69XpemCUbSiUwqbUU9vQ/ywc4P/nHqiXujxL1G/YBO9wZBnkkkBAR9aWE8Mdb5KvgoCqlBp92fUBcCtplMZlwLem3ltfpep9ecuNCIAR4yokWqUlIaObCeCloxUbv6LAqK1p9Ft4NMsE3LY4nS9VO1Q9sLl1I3mSOzr5xJJIPMRhWMxId4adaKGjfXJgazU3fWYmLi8NAL57Zb/7GyJRMk+xOWh2jdXTn1o8/nOlO3WxvPpg61ntybylSPpFpJWuYyE6v3Hqn8WPrG0n1USAa9zIe1X/win0jdu91f0naiN5O8MxZtvlOpNRuBVO835Wu/yowymZXV/oRyYyETO2/U1ivf6sRCLXb+KXrzViaYBte2yvBdb+pbLTu3ptGBA0lupyst7WymMo8cVSpXrh9gvsrSpbPUWGfV+6TVdnohCBIHhZncXad3JH/A2U3wRvW1zl/d/suxd//PJaIn5kQ3msTYWpH2tV5u/bsnGq+mLp25jAYvtxYeW/LWtWwkCA/4BML3G4OgyB1bKHIEA4PQqDXqWiORpArdQ36N5MhztT+lcoN+q9JoWo0QJTLFVCL639Iw+wMWfWh1iDE2hgAAAABJRU5ErkJggg==\\n\", \"height\": 48, \"channels\": 1, \"width\": 48, \"type\": \"image\", \"id\": 716540280}, {\"format\": \"png\", \"value\": \"image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAAAAAByaaZbAAACLklEQVRIiZ3WyXIjNxCE4Q9oriIpWQtn3sHv/1K2JVK2uKkbQPnAjrlP44yIDFT+lYn0pzfFQdVkM0WTJZ0OSWBQEDq97DfPbOEimwu9Dp0ZKqqEQPYgDEgTFB4NTi6qwU7SG3SaJknCTLGyc1FUeYLCv9o4ibkHPUgW5ope0izMnIWmiQkK33pJyBbC3FmysLM2d/QpW6iyq6KpExR6oZdlTaiqtZWdR71X2X+KqlfQJvkAyVKvuQkra8+esJK9So6qhqXLJB8ISS+ht7DyhxeDIus0T4qD0NyY5MOd/6yhs/TixaB3wcZa9iZ8jJthgkJF0XSWlp486/WublbOwkb2U/LPyNzvK4TF6O/S3qticHXTobnJNvgheTdMcjpUydrK3puiufo2kzRJ9aV5xB5/T3xDs7L05qcinNxkWQhJE66ylfBDc5zE0tzCi1dNdXI2k9D9utJ8KXbYT5rSzMqbvaw5+dLphDuXoVM04WxrrnqepBCWipWmWapiJLNKyviahTtxp4kbd7BwtfHgZtCETtNpCM3WUsVhkg9ZdZDssUYoY3bHmN9ra0U4+HSboNAkzUHzbGsrO6uqkBUzGw9I3n24Tuq4GDP1oAphK3z7VsZuWAvJp6Ob2ySWhjGTsuM4lw2qUDzaYO4vBxffmLJx98akyT6E0OxwNTfXJO/end00JjVQSOMGF8m7+y9gayYkd35OLkJMTD6/+CeNfVMVW034cnBy0ka9CT78DwejIycgT9IrAAAAAElFTkSuQmCC\\n\", \"height\": 48, \"channels\": 1, \"width\": 48, \"type\": \"image\", \"id\": 716540336}, {\"format\": \"png\", \"value\": \"image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAAAAAByaaZbAAACUklEQVRIib3UW24bBRTG8d94Lh7bsRtfmiYhpKUqgpJEvFWCCvHCatgRS2AXBQkBQqqKBCU0CERK3Si3Opbry9gzwwNswH7w2cD/+59z9AVfolSKhLoybux57MRPhqZmFHJthcRCqWLJiQq5hcBMohSQu/HYqaFrQx1yibGakdhiBUJuIVeYKxQQynztTGCmKaAhNhGLBYLlCctHmprL5eYm9iF25isdTTUDGYWKyKWAVSJFY1MTMxWlXIWha5whFJiQSlVVBSrCdUifm5kIhDblInIVu94auKUlJtHRFYlWJIwEamJjsVSNK5lDc0/N1XVJvKNmQ6FUWYd0KhaYKmTq+gwc+dAbf7lS12bTLbcRKlci5KZyuZpS3wt6PhDbd+SJG1s03dZUU/yvveQsH2koEknV1PVtk2hLZD428kSfqqpdkchMvAKhJpVKdex67prPbClUXDjy2jGhjlhNIFasQGir29DUc27iIYf+0HGOew5M+NMdVbEQ2TrWuqWlouGVCx0PuPKbXOmRhm3vcunUzz5XiFcq47pEEwulng6XRp76RMvclh6bxl5oeoRkHdJjGzYVBjL3dLlAR2qqbuIjhr73t/su7ax06bcWOn41dGjfnExLS8PEL17a4cDYt565qyVdh/TAvlMnug6kQrYl9pR+9Lu6M9oOvPLcXXdWae/ojRM7tlUs1L2kj4XX+gp9Vf7xnocGvtH0xTqkH3jfsZFP3TfVo4eRPVMzpZKG0MSGgR/sr0S4MRBb+E5owVhqgLnMTP7f4wcymdjx8oR/AULo1xIVPAX2AAAAAElFTkSuQmCC\\n\", \"height\": 48, \"channels\": 1, \"width\": 48, \"type\": \"image\", \"id\": 716540392}], \"selected_variable\": {\"name\": [\"<SArray>\"], \"dtype\": \"Image\", \"view_component\": \"Images\", \"view_file\": \"sarray\", \"descriptives\": {\"rows\": 39209}, \"type\": \"SArray\", \"view_components\": [\"Images\"]}}, e);\n",
       "                });\n",
       "            })();\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ciresan_train['image'].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiền xử lý ảnh theo slides: http://vision.ia.ac.cn/zh/senimar/reports/ConvNet-slide-luohl.pdf (trang 21-22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ciresan_train['image'] = gl.image_analysis.resize(ciresan_train['image'], 32,32, channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canvas is updated and available in a tab in the default browser.\n"
     ]
    }
   ],
   "source": [
    "ciresan_train['image'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from skimage import exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-9a48e4231e12>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclahe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreateCLAHE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclipLimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtileGridSize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mciresan_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mciresan_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSArray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexposure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequalize_adapthist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpixel_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\admin\\AppData\\Local\\Dato\\Dato Launcher\\lib\\site-packages\\graphlab\\data_structures\\sarray.pyc\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, fn, dtype, skip_undefined, seed)\u001b[0m\n\u001b[0;32m   1669\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Input function must be callable.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1671\u001b[1;33m         \u001b[0mdryrun\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1672\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1673\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfer_type_of_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdryrun\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-9a48e4231e12>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(im)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclahe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreateCLAHE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclipLimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtileGridSize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mciresan_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mciresan_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSArray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexposure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequalize_adapthist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpixel_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "ciresan_train['image'] = ciresan_train['image'].apply(lambda im: gl.SArray(exposure.equalize_adapthist(im.pixel_data())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">path</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">image</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 48 Width: 48</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 48 Width: 48</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 48 Width: 48</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 48 Width: 48</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 48 Width: 48</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 48 Width: 48</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 48 Width: 48</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 48 Width: 48</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 48 Width: 48</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 48 Width: 48</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">26</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[39209 rows x 3 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tpath\tstr\n",
       "\timage\tImage\n",
       "\tlabel\tint\n",
       "\n",
       "Rows: 39209\n",
       "\n",
       "Data:\n",
       "+-------------------------------+----------------------+-------+\n",
       "|              path             |        image         | label |\n",
       "+-------------------------------+----------------------+-------+\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 48 Width: 48 |   18  |\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 48 Width: 48 |   8   |\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 48 Width: 48 |   24  |\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 48 Width: 48 |   15  |\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 48 Width: 48 |   9   |\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 48 Width: 48 |   5   |\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 48 Width: 48 |   38  |\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 48 Width: 48 |   6   |\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 48 Width: 48 |   10  |\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 48 Width: 48 |   26  |\n",
       "+-------------------------------+----------------------+-------+\n",
       "[39209 rows x 3 columns]\n",
       "Note: Only the head of the SFrame is printed.\n",
       "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns."
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ciresan_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canvas is updated and available in a tab in the default browser.\n"
     ]
    }
   ],
   "source": [
    "ciresan_train['image'].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dữ liệu kiểm tra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ciresan_test= gl.SFrame('test_sframe/')\n",
    "ciresan_test['image'] = gl.image_analysis.resize(ciresan_test['image'], 48,48, channels=1)#28 cho Lenet, 30 cho mạng dato 1000 lượt, \n",
    "#48 cho idsia net "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">path</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">image</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 30 Width: 30</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 30 Width: 30</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 30 Width: 30</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 30 Width: 30</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 30 Width: 30</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 30 Width: 30</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 30 Width: 30</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 30 Width: 30</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 30 Width: 30</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 30 Width: 30</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[12630 rows x 3 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tpath\tstr\n",
       "\timage\tImage\n",
       "\tlabel\tint\n",
       "\n",
       "Rows: 12630\n",
       "\n",
       "Data:\n",
       "+-------------------------------+----------------------+-------+\n",
       "|              path             |        image         | label |\n",
       "+-------------------------------+----------------------+-------+\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 30 Width: 30 |   26  |\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 30 Width: 30 |   8   |\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 30 Width: 30 |   17  |\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 30 Width: 30 |   38  |\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 30 Width: 30 |   35  |\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 30 Width: 30 |   42  |\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 30 Width: 30 |   17  |\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 30 Width: 30 |   4   |\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 30 Width: 30 |   1   |\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 30 Width: 30 |   2   |\n",
       "+-------------------------------+----------------------+-------+\n",
       "[12630 rows x 3 columns]\n",
       "Note: Only the head of the SFrame is printed.\n",
       "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ciresan_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canvas is accessible via web browser at the URL: http://localhost:55456/index.html\n",
      "Opening Canvas in default web browser.\n"
     ]
    }
   ],
   "source": [
    "gl.canvas.set_target('browser')\n",
    "ciresan_test['image'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ciresan_test['image'] = gl.image_analysis.resize(ciresan_test['image'], 32,32, channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canvas is accessible via web browser at the URL: http://localhost:55456/index.html\n",
      "Opening Canvas in default web browser.\n"
     ]
    }
   ],
   "source": [
    "ciresan_test['image'].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thiết kế lại mạng theo bài báo Ciresan et al '11:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN theo slides của bọn Khựa: http://vision.ia.ac.cn/zh/senimar/reports/ConvNet-slide-luohl.pdf trang 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ConvolutionLayer\n",
       "   init_random = gaussian\n",
       "   padding = 0\n",
       "   stride = 1\n",
       "   num_channels = 16\n",
       "   num_groups = 1\n",
       "   kernel_size = 5]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reproduced_net = list()\n",
    "#import graphlab\n",
    "reproduced_net.append(gl.deeplearning.layers.ConvolutionLayer(kernel_size=5,\n",
    "                                                                    #stride=1,\n",
    "                                                                    num_channels=16))\n",
    "reproduced_net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ConvolutionLayer\n",
       "   init_random = gaussian\n",
       "   padding = 0\n",
       "   stride = 1\n",
       "   num_channels = 16\n",
       "   num_groups = 1\n",
       "   kernel_size = 5, TanhLayer]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reproduced_net.append(gl.deeplearning.layers.TanhLayer())\n",
    "reproduced_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ConvolutionLayer\n",
       "   init_random = gaussian\n",
       "   padding = 0\n",
       "   stride = 1\n",
       "   num_channels = 16\n",
       "   num_groups = 1\n",
       "   kernel_size = 5, TanhLayer, MaxPoolingLayer\n",
       "   padding = 0\n",
       "   stride = 2\n",
       "   kernel_size = 2]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reproduced_net.append(gl.deeplearning.layers.MaxPoolingLayer(kernel_size=2,\n",
    "                                                            stride=2))\n",
    "reproduced_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ConvolutionLayer\n",
       "   init_random = gaussian\n",
       "   padding = 0\n",
       "   stride = 1\n",
       "   num_channels = 16\n",
       "   num_groups = 1\n",
       "   kernel_size = 5, TanhLayer, MaxPoolingLayer\n",
       "   padding = 0\n",
       "   stride = 2\n",
       "   kernel_size = 2, ConvolutionLayer\n",
       "   init_random = gaussian\n",
       "   padding = 0\n",
       "   stride = 1\n",
       "   num_channels = 32\n",
       "   num_groups = 1\n",
       "   kernel_size = 5]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reproduced_net.append(gl.deeplearning.layers.ConvolutionLayer(kernel_size=5,\n",
    "                                                                    #stride=1,\n",
    "                                                                    num_channels=32))\n",
    "reproduced_net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ConvolutionLayer\n",
       "   init_random = gaussian\n",
       "   padding = 0\n",
       "   stride = 1\n",
       "   num_channels = 16\n",
       "   num_groups = 1\n",
       "   kernel_size = 5, TanhLayer, MaxPoolingLayer\n",
       "   padding = 0\n",
       "   stride = 2\n",
       "   kernel_size = 2, ConvolutionLayer\n",
       "   init_random = gaussian\n",
       "   padding = 0\n",
       "   stride = 1\n",
       "   num_channels = 32\n",
       "   num_groups = 1\n",
       "   kernel_size = 5, TanhLayer, MaxPoolingLayer\n",
       "   padding = 0\n",
       "   stride = 2\n",
       "   kernel_size = 2]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reproduced_net.append(gl.deeplearning.layers.TanhLayer())\n",
    "reproduced_net\n",
    "reproduced_net.append(gl.deeplearning.layers.MaxPoolingLayer(kernel_size=2,\n",
    "                                                            stride=2))\n",
    "reproduced_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ConvolutionLayer\n",
       "   init_random = gaussian\n",
       "   padding = 0\n",
       "   stride = 1\n",
       "   num_channels = 16\n",
       "   num_groups = 1\n",
       "   kernel_size = 5, TanhLayer, MaxPoolingLayer\n",
       "   padding = 0\n",
       "   stride = 2\n",
       "   kernel_size = 2, ConvolutionLayer\n",
       "   init_random = gaussian\n",
       "   padding = 0\n",
       "   stride = 1\n",
       "   num_channels = 32\n",
       "   num_groups = 1\n",
       "   kernel_size = 5, TanhLayer, MaxPoolingLayer\n",
       "   padding = 0\n",
       "   stride = 2\n",
       "   kernel_size = 2, FlattenLayer, FullConnectionLayer\n",
       "   init_sigma = 0.01\n",
       "   init_random = gaussian\n",
       "   init_bias = 0\n",
       "   num_hidden_units = 256, TanhLayer, FullConnectionLayer\n",
       "   init_sigma = 0.01\n",
       "   init_random = gaussian\n",
       "   init_bias = 0\n",
       "   num_hidden_units = 43]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reproduced_net.append(gl.deeplearning.layers.FlattenLayer())\n",
    "reproduced_net.append(gl.deeplearning.layers.FullConnectionLayer(256))\n",
    "reproduced_net.append(gl.deeplearning.layers.TanhLayer())\n",
    "reproduced_net.append(gl.deeplearning.layers.FullConnectionLayer(43))\n",
    "reproduced_net\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "layer[0]: ConvolutionLayer\n",
       "  init_random = gaussian\n",
       "  padding = 0\n",
       "  stride = 1\n",
       "  num_channels = 16\n",
       "  num_groups = 1\n",
       "  kernel_size = 5\n",
       "layer[1]: TanhLayer\n",
       "layer[2]: MaxPoolingLayer\n",
       "  padding = 0\n",
       "  stride = 2\n",
       "  kernel_size = 2\n",
       "layer[3]: ConvolutionLayer\n",
       "  init_random = gaussian\n",
       "  padding = 0\n",
       "  stride = 1\n",
       "  num_channels = 32\n",
       "  num_groups = 1\n",
       "  kernel_size = 5\n",
       "layer[4]: TanhLayer\n",
       "layer[5]: MaxPoolingLayer\n",
       "  padding = 0\n",
       "  stride = 2\n",
       "  kernel_size = 2\n",
       "layer[6]: FlattenLayer\n",
       "layer[7]: FullConnectionLayer\n",
       "  init_sigma = 0.01\n",
       "  init_random = gaussian\n",
       "  init_bias = 0\n",
       "  num_hidden_units = 256\n",
       "layer[8]: TanhLayer\n",
       "layer[9]: FullConnectionLayer\n",
       "  init_sigma = 0.01\n",
       "  init_random = gaussian\n",
       "  init_bias = 0\n",
       "  num_hidden_units = 43"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reproduced_layers = reproduced_net\n",
    "reproduced_net = gl.deeplearning.NeuralNet()\n",
    "reproduced_net.layers = reproduced_layers\n",
    "reproduced_net.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "layer[0]: ConvolutionLayer\n",
       "  init_random = gaussian\n",
       "  padding = 0\n",
       "  stride = 1\n",
       "  num_channels = 16\n",
       "  num_groups = 1\n",
       "  kernel_size = 5\n",
       "layer[1]: TanhLayer\n",
       "layer[2]: MaxPoolingLayer\n",
       "  padding = 0\n",
       "  stride = 2\n",
       "  kernel_size = 2\n",
       "layer[3]: ConvolutionLayer\n",
       "  init_random = gaussian\n",
       "  padding = 0\n",
       "  stride = 1\n",
       "  num_channels = 32\n",
       "  num_groups = 1\n",
       "  kernel_size = 5\n",
       "layer[4]: TanhLayer\n",
       "layer[5]: MaxPoolingLayer\n",
       "  padding = 0\n",
       "  stride = 2\n",
       "  kernel_size = 2\n",
       "layer[6]: FlattenLayer\n",
       "layer[7]: FullConnectionLayer\n",
       "  init_sigma = 0.01\n",
       "  init_random = gaussian\n",
       "  init_bias = 0\n",
       "  num_hidden_units = 256\n",
       "layer[8]: TanhLayer\n",
       "layer[9]: FullConnectionLayer\n",
       "  init_sigma = 0.01\n",
       "  init_random = gaussian\n",
       "  init_bias = 0\n",
       "  num_hidden_units = 43\n",
       "layer[10]: SoftmaxLayer"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reproduced_net.layers.append(gl.deeplearning.layers.SoftmaxLayer())\n",
    "reproduced_net.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reproduced_net.verify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trained_reproduced = gl.neuralnet_classifier.create(ciresan_train, target='label',\n",
    "                                             features=['image'],\n",
    "                                             network= reproduced_net,\n",
    "                                             max_iterations=3,\n",
    "                                              model_checkpoint_path ='reproduced net 3',\n",
    "                                              model_checkpoint_interval =1\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mạng của Dato dựa trên dữ liệu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dato_net = gl.deeplearning.create(ciresan_train, target='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "### network layers ###\n",
       "layer[0]: ConvolutionLayer\n",
       "  init_random = gaussian\n",
       "  padding = 0\n",
       "  stride = 2\n",
       "  num_channels = 10\n",
       "  num_groups = 1\n",
       "  kernel_size = 3\n",
       "layer[1]: MaxPoolingLayer\n",
       "  padding = 0\n",
       "  stride = 2\n",
       "  kernel_size = 3\n",
       "layer[2]: FlattenLayer\n",
       "layer[3]: FullConnectionLayer\n",
       "  init_sigma = 0.01\n",
       "  init_random = gaussian\n",
       "  init_bias = 0\n",
       "  num_hidden_units = 100\n",
       "layer[4]: RectifiedLinearLayer\n",
       "layer[5]: DropoutLayer\n",
       "  threshold = 0.5\n",
       "layer[6]: FullConnectionLayer\n",
       "  init_sigma = 0.01\n",
       "  init_random = gaussian\n",
       "  init_bias = 0\n",
       "  num_hidden_units = 43\n",
       "layer[7]: SoftmaxLayer\n",
       "### end network layers ###\n",
       "\n",
       "### network parameters ###\n",
       "learning_rate = 0.001\n",
       "momentum = 0.9\n",
       "### end network parameters ###"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"dato_net.layers[0].num_channels=100\n",
    "dato_net.layers[0].kernel_size=7\n",
    "dato_net.layers[0].stride=1\n",
    "\"\"\"\n",
    "#dato_net.layers[1].kernel_size=2\n",
    "dato_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using network:\n",
      "\n",
      "### network layers ###\n",
      "layer[0]: ConvolutionLayer\n",
      "  init_random = gaussian\n",
      "  padding = 0\n",
      "  stride = 2\n",
      "  num_channels = 10\n",
      "  num_groups = 1\n",
      "  kernel_size = 3\n",
      "layer[1]: MaxPoolingLayer\n",
      "  padding = 0\n",
      "  stride = 2\n",
      "  kernel_size = 3\n",
      "layer[2]: FlattenLayer\n",
      "layer[3]: FullConnectionLayer\n",
      "  init_sigma = 0.01\n",
      "  init_random = gaussian\n",
      "  init_bias = 0\n",
      "  num_hidden_units = 100\n",
      "layer[4]: RectifiedLinearLayer\n",
      "layer[5]: DropoutLayer\n",
      "  threshold = 0.5\n",
      "layer[6]: FullConnectionLayer\n",
      "  init_sigma = 0.01\n",
      "  init_random = gaussian\n",
      "  init_bias = 0\n",
      "  num_hidden_units = 43\n",
      "layer[7]: SoftmaxLayer\n",
      "### end network layers ###\n",
      "\n",
      "### network parameters ###\n",
      "model_checkpoint_interval = 1\n",
      "learning_rate = 0.001\n",
      "momentum = 0.9\n",
      "model_checkpoint_path = dato net 3\n",
      "### end network parameters ###\n",
      "\n",
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trained_dato = gl.neuralnet_classifier.create(ciresan_train, target='label',\n",
    "                                             features=['image'],\n",
    "                                             network= dato_net,\n",
    "                                             max_iterations=3,\n",
    "                                              model_checkpoint_path ='dato net 3',\n",
    "                                              model_checkpoint_interval =1\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7955661416053772, 'confusion_matrix': Columns:\n",
       " \ttarget_label\tint\n",
       " \tpredicted_label\tint\n",
       " \tcount\tint\n",
       " \n",
       " Rows: 382\n",
       " \n",
       " Data:\n",
       " +--------------+-----------------+-------+\n",
       " | target_label | predicted_label | count |\n",
       " +--------------+-----------------+-------+\n",
       " |      0       |        0        |   18  |\n",
       " |      1       |        0        |   1   |\n",
       " |      4       |        0        |   1   |\n",
       " |      37      |        0        |   1   |\n",
       " |      0       |        1        |   16  |\n",
       " |      1       |        1        |  601  |\n",
       " |      2       |        1        |   30  |\n",
       " |      3       |        1        |   8   |\n",
       " |      4       |        1        |   24  |\n",
       " |      5       |        1        |   9   |\n",
       " +--------------+-----------------+-------+\n",
       " [382 rows x 3 columns]\n",
       " Note: Only the head of the SFrame is printed.\n",
       " You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_dato.evaluate(ciresan_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nhớ thêm module deeplearning vào! mới load được\n",
    "\n",
    "# Load lại IDSIA net, theo bài committee của Schmidhuber và các cộng sự: http://people.idsia.ch/~ciresan/data/ijcnn2011.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A newer version of GraphLab Create (v1.9) is available! Your current version is v1.8.3.\n",
      "\n",
      "You can use pip to upgrade the graphlab-create package. For more information see https://dato.com/products/create/upgrade.\n",
      "[INFO] GraphLab Create v1.8.3 started. Logging: C:\\Users\\admin\\AppData\\Local\\Temp\\graphlab_server_1464345854.log.0\n"
     ]
    }
   ],
   "source": [
    "import graphlab as gl\n",
    "idsia_net = gl.deeplearning.load('ciresan neural net for traffic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idsia_net.layers[0].init_random='xavier'\n",
    "idsia_net.layers[1] = gl.deeplearning.layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idsia_net.params['init_random']='xavier'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'init_random': 'xavier', 'learning_rate': 0.001, 'momentum': 0.9}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idsia_net.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name mxnet",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-16ecb5783399>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgraphlab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmxnet\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name mxnet"
     ]
    }
   ],
   "source": [
    "from graphlab import mxnet as mx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "### network layers ###\n",
       "layer[0]: ConvolutionLayer\n",
       "  init_random = gaussian\n",
       "  padding = 0\n",
       "  stride = 1\n",
       "  num_channels = 100\n",
       "  num_groups = 1\n",
       "  kernel_size = 3\n",
       "layer[1]: RectifiedLinearLayer\n",
       "layer[2]: MaxPoolingLayer\n",
       "  padding = 0\n",
       "  stride = 2\n",
       "  kernel_size = 2\n",
       "layer[3]: ConvolutionLayer\n",
       "  init_random = gaussian\n",
       "  padding = 0\n",
       "  stride = 1\n",
       "  num_channels = 150\n",
       "  num_groups = 1\n",
       "  kernel_size = 4\n",
       "layer[4]: RectifiedLinearLayer\n",
       "layer[5]: MaxPoolingLayer\n",
       "  padding = 0\n",
       "  stride = 2\n",
       "  kernel_size = 2\n",
       "layer[6]: ConvolutionLayer\n",
       "  init_random = gaussian\n",
       "  padding = 0\n",
       "  stride = 1\n",
       "  num_channels = 250\n",
       "  num_groups = 1\n",
       "  kernel_size = 3\n",
       "layer[7]: RectifiedLinearLayer\n",
       "layer[8]: MaxPoolingLayer\n",
       "  padding = 0\n",
       "  stride = 2\n",
       "  kernel_size = 2\n",
       "layer[9]: FlattenLayer\n",
       "layer[10]: FullConnectionLayer\n",
       "  init_sigma = 0.01\n",
       "  init_random = gaussian\n",
       "  init_bias = 0\n",
       "  num_hidden_units = 200\n",
       "layer[11]: RectifiedLinearLayer\n",
       "layer[12]: FullConnectionLayer\n",
       "  init_sigma = 0.01\n",
       "  init_random = gaussian\n",
       "  init_bias = 0\n",
       "  num_hidden_units = 43\n",
       "layer[13]: SoftmaxLayer\n",
       "### end network layers ###\n",
       "\n",
       "### network parameters ###\n",
       "learning_rate = 0.001\n",
       "init_random = xavier\n",
       "momentum = 0.9\n",
       "### end network parameters ###"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idsia_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idsia_net.verify(input_shape=(48,48,1), output_shape=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trained_idsia = gl.neuralnet_classifier.create(dataset = ciresan_train,\n",
    "                                            target = 'label',\n",
    "                                            features= ['image'],\n",
    "                                             max_iterations=1,\n",
    "                                            network = idsia_net,\n",
    "                                            model_checkpoint_path ='idsia net xavier 1',\n",
    "                                              model_checkpoint_interval =1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thiết kế IDSIA net:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ">>> conv_net = gl.deeplearning.ConvolutionNet(num_convolution_layers=1,\n",
    "                                              kernel_size=3,\n",
    "                                              num_channels=100,\n",
    "                                              num_output_units=43)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "### network layers ###\n",
       "layer[0]: ConvolutionLayer\n",
       "  init_random = gaussian\n",
       "  padding = 0\n",
       "  stride = 1\n",
       "  num_channels = 100\n",
       "  num_groups = 1\n",
       "  kernel_size = 3\n",
       "layer[1]: MaxPoolingLayer\n",
       "  padding = 0\n",
       "  stride = 1\n",
       "  kernel_size = 3\n",
       "layer[2]: FlattenLayer\n",
       "layer[3]: FullConnectionLayer\n",
       "  init_sigma = 0.01\n",
       "  init_random = gaussian\n",
       "  init_bias = 0\n",
       "  num_hidden_units = 43\n",
       "layer[4]: SoftmaxLayer\n",
       "### end network layers ###\n",
       "\n",
       "### network parameters ###\n",
       "learning_rate = 0.001\n",
       "momentum = 0.9\n",
       "### end network parameters ###"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Computing mean image...</pre>"
      ],
      "text/plain": [
       "Computing mean image..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Done computing mean image.</pre>"
      ],
      "text/plain": [
       "Done computing mean image."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Creating neuralnet using cpu</pre>"
      ],
      "text/plain": [
       "Creating neuralnet using cpu"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Training with batch size = 100</pre>"
      ],
      "text/plain": [
       "Training with batch size = 100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+--------------+-------------------+---------------------+-----------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+--------------+-------------------+---------------------+-----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Examples | Elapsed Time | Training-accuracy | Validation-accuracy | Examples/second |</pre>"
      ],
      "text/plain": [
       "| Iteration | Examples | Elapsed Time | Training-accuracy | Validation-accuracy | Examples/second |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+--------------+-------------------+---------------------+-----------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+--------------+-------------------+---------------------+-----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 100      | 17.450620    | 0.060000          |                     | 5.730472        |</pre>"
      ],
      "text/plain": [
       "| 1         | 100      | 17.450620    | 0.060000          |                     | 5.730472        |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 200      | 33.883505    | 0.050000          |                     | 6.085354        |</pre>"
      ],
      "text/plain": [
       "| 1         | 200      | 33.883505    | 0.050000          |                     | 6.085354        |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 300      | 51.413959    | 0.046667          |                     | 5.704356        |</pre>"
      ],
      "text/plain": [
       "| 1         | 300      | 51.413959    | 0.046667          |                     | 5.704356        |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 400      | 67.674863    | 0.035000          |                     | 6.149721        |</pre>"
      ],
      "text/plain": [
       "| 1         | 400      | 67.674863    | 0.035000          |                     | 6.149721        |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 500      | 83.461144    | 0.046000          |                     | 6.334614        |</pre>"
      ],
      "text/plain": [
       "| 1         | 500      | 83.461144    | 0.046000          |                     | 6.334614        |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 600      | 99.516767    | 0.046667          |                     | 6.228347        |</pre>"
      ],
      "text/plain": [
       "| 1         | 600      | 99.516767    | 0.046667          |                     | 6.228347        |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 700      | 117.902396   | 0.047143          |                     | 5.439032        |</pre>"
      ],
      "text/plain": [
       "| 1         | 700      | 117.902396   | 0.047143          |                     | 5.439032        |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 800      | 135.120448   | 0.045000          |                     | 5.807862        |</pre>"
      ],
      "text/plain": [
       "| 1         | 800      | 135.120448   | 0.045000          |                     | 5.807862        |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 900      | 151.471496   | 0.047778          |                     | 6.115810        |</pre>"
      ],
      "text/plain": [
       "| 1         | 900      | 151.471496   | 0.047778          |                     | 6.115810        |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 1000     | 166.810457   | 0.046000          |                     | 6.519352        |</pre>"
      ],
      "text/plain": [
       "| 1         | 1000     | 166.810457   | 0.046000          |                     | 6.519352        |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 1100     | 186.439592   | 0.043636          |                     | 5.094464        |</pre>"
      ],
      "text/plain": [
       "| 1         | 1100     | 186.439592   | 0.043636          |                     | 5.094464        |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 1200     | 202.881618   | 0.044167          |                     | 6.081978        |</pre>"
      ],
      "text/plain": [
       "| 1         | 1200     | 202.881618   | 0.044167          |                     | 6.081978        |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trained_convnet = gl.neuralnet_classifier.create(ciresan_train, target='label',\n",
    "                                             features=['image'],\n",
    "                                             network= conv_net,\n",
    "                                             max_iterations=3,\n",
    "                                              model_checkpoint_path ='conv net 3',\n",
    "                                              model_checkpoint_interval =1\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chạy Lenet, Alexnet trên bộ này:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A newer version of GraphLab Create (v1.9) is available! Your current version is v1.8.3.\n",
      "\n",
      "You can use pip to upgrade the graphlab-create package. For more information see https://dato.com/products/create/upgrade.\n"
     ]
    }
   ],
   "source": [
    "import graphlab as gl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lenet = gl.deeplearning.get_builtin_neuralnet('mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sửa lại để output đầu ra 43 lớp:\n",
    "(Đừng sửa lại số kernels=10 vì nghĩ rằng 10*3=30 sẽ chạy được :)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lenet.layers[-2].num_hidden_units=43#['output_shape']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đây đâu phải Lenet-5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenet.verify(input_shape=(28,28,1), output_shape=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "### network layers ###\n",
       "layer[0]: ConvolutionLayer\n",
       "  init_random = xavier\n",
       "  padding = 1\n",
       "  stride = 2\n",
       "  num_channels = 32\n",
       "  num_groups = 1\n",
       "  kernel_size = 3\n",
       "layer[1]: MaxPoolingLayer\n",
       "  padding = 0\n",
       "  stride = 2\n",
       "  kernel_size = 3\n",
       "layer[2]: FlattenLayer\n",
       "layer[3]: DropoutLayer\n",
       "  threshold = 0.5\n",
       "layer[4]: FullConnectionLayer\n",
       "  init_sigma = 0.01\n",
       "  init_random = gaussian\n",
       "  init_bias = 0\n",
       "  num_hidden_units = 100\n",
       "layer[5]: SigmoidLayer\n",
       "layer[6]: FullConnectionLayer\n",
       "  init_sigma = 0.01\n",
       "  init_random = gaussian\n",
       "  init_bias = 0\n",
       "  num_hidden_units = 43\n",
       "layer[7]: SoftmaxLayer\n",
       "### end network layers ###\n",
       "\n",
       "### network parameters ###\n",
       "init_random = gaussian\n",
       "learning_rate = 0.1\n",
       "input_shape = 1,28,28\n",
       "batch_size = 100\n",
       "divideby = 255\n",
       "l2_regularization = 0.0\n",
       "momentum = 0.9\n",
       "### end network parameters ###"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1,28,28'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenet.params['input_shape']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Computing mean image...</pre>"
      ],
      "text/plain": [
       "Computing mean image..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Done computing mean image.</pre>"
      ],
      "text/plain": [
       "Done computing mean image."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Creating neuralnet using cpu</pre>"
      ],
      "text/plain": [
       "Creating neuralnet using cpu"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Training with batch size = 100</pre>"
      ],
      "text/plain": [
       "Training with batch size = 100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+--------------+-------------------+---------------------+-----------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+--------------+-------------------+---------------------+-----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Examples | Elapsed Time | Training-accuracy | Validation-accuracy | Examples/second |</pre>"
      ],
      "text/plain": [
       "| Iteration | Examples | Elapsed Time | Training-accuracy | Validation-accuracy | Examples/second |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+--------------+-------------------+---------------------+-----------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+--------------+-------------------+---------------------+-----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 3300     | 10.247171    | 0.064545          |                     | 322.041534      |</pre>"
      ],
      "text/plain": [
       "| 1         | 3300     | 10.247171    | 0.064545          |                     | 322.041534      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 6500     | 20.549023    | 0.063231          |                     | 310.623505      |</pre>"
      ],
      "text/plain": [
       "| 1         | 6500     | 20.549023    | 0.063231          |                     | 310.623505      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 9900     | 30.785755    | 0.071616          |                     | 332.137146      |</pre>"
      ],
      "text/plain": [
       "| 1         | 9900     | 30.785755    | 0.071616          |                     | 332.137146      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 13200    | 41.169910    | 0.073182          |                     | 317.791840      |</pre>"
      ],
      "text/plain": [
       "| 1         | 13200    | 41.169910    | 0.073182          |                     | 317.791840      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 16600    | 51.270661    | 0.081928          |                     | 336.608521      |</pre>"
      ],
      "text/plain": [
       "| 1         | 16600    | 51.270661    | 0.081928          |                     | 336.608521      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 19900    | 61.583301    | 0.093668          |                     | 319.996002      |</pre>"
      ],
      "text/plain": [
       "| 1         | 19900    | 61.583301    | 0.093668          |                     | 319.996002      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 23200    | 71.617672    | 0.109224          |                     | 328.869476      |</pre>"
      ],
      "text/plain": [
       "| 1         | 23200    | 71.617672    | 0.109224          |                     | 328.869476      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 26600    | 81.866401    | 0.132180          |                     | 331.748444      |</pre>"
      ],
      "text/plain": [
       "| 1         | 26600    | 81.866401    | 0.132180          |                     | 331.748444      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 30000    | 91.963745    | 0.156233          |                     | 336.722107      |</pre>"
      ],
      "text/plain": [
       "| 1         | 30000    | 91.963745    | 0.156233          |                     | 336.722107      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 33400    | 102.242450   | 0.179790          |                     | 330.781219      |</pre>"
      ],
      "text/plain": [
       "| 1         | 33400    | 102.242450   | 0.179790          |                     | 330.781219      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 36500    | 112.270853   | 0.200959          |                     | 309.121887      |</pre>"
      ],
      "text/plain": [
       "| 1         | 36500    | 112.270853   | 0.200959          |                     | 309.121887      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 37300    | 117.109848   | 0.206220          | 0.495200            | 165.323212      |</pre>"
      ],
      "text/plain": [
       "| 1         | 37300    | 117.109848   | 0.206220          | 0.495200            | 165.323212      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Checkpointing model into lenet 3</pre>"
      ],
      "text/plain": [
       "Checkpointing model into lenet 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 3400     | 127.141016   | 0.447941          |                     | 338.951813      |</pre>"
      ],
      "text/plain": [
       "| 2         | 3400     | 127.141016   | 0.447941          |                     | 338.951813      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 6600     | 137.271024   | 0.457121          |                     | 315.892883      |</pre>"
      ],
      "text/plain": [
       "| 2         | 6600     | 137.271024   | 0.457121          |                     | 315.892883      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 9700     | 147.401186   | 0.478557          |                     | 306.016815      |</pre>"
      ],
      "text/plain": [
       "| 2         | 9700     | 147.401186   | 0.478557          |                     | 306.016815      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 13100    | 157.625348   | 0.485649          |                     | 332.545624      |</pre>"
      ],
      "text/plain": [
       "| 2         | 13100    | 157.625348   | 0.485649          |                     | 332.545624      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 16500    | 167.661701   | 0.490909          |                     | 338.768402      |</pre>"
      ],
      "text/plain": [
       "| 2         | 16500    | 167.661701   | 0.490909          |                     | 338.768402      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 19700    | 177.921313   | 0.498122          |                     | 311.902618      |</pre>"
      ],
      "text/plain": [
       "| 2         | 19700    | 177.921313   | 0.498122          |                     | 311.902618      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 22600    | 187.939628   | 0.503496          |                     | 289.469757      |</pre>"
      ],
      "text/plain": [
       "| 2         | 22600    | 187.939628   | 0.503496          |                     | 289.469757      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 25900    | 198.133078   | 0.511737          |                     | 323.737488      |</pre>"
      ],
      "text/plain": [
       "| 2         | 25900    | 198.133078   | 0.511737          |                     | 323.737488      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 29200    | 208.182231   | 0.520856          |                     | 328.385925      |</pre>"
      ],
      "text/plain": [
       "| 2         | 29200    | 208.182231   | 0.520856          |                     | 328.385925      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 32500    | 218.325703   | 0.527231          |                     | 325.332428      |</pre>"
      ],
      "text/plain": [
       "| 2         | 32500    | 218.325703   | 0.527231          |                     | 325.332428      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 35600    | 228.505783   | 0.532865          |                     | 304.517822      |</pre>"
      ],
      "text/plain": [
       "| 2         | 35600    | 228.505783   | 0.532865          |                     | 304.517822      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 37300    | 236.313664   | 0.537185          | 0.665993            | 217.726974      |</pre>"
      ],
      "text/plain": [
       "| 2         | 37300    | 236.313664   | 0.537185          | 0.665993            | 217.726974      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Checkpointing model into lenet 3</pre>"
      ],
      "text/plain": [
       "Checkpointing model into lenet 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 3100     | 246.548166   | 0.624194          |                     | 302.903900      |</pre>"
      ],
      "text/plain": [
       "| 3         | 3100     | 246.548166   | 0.624194          |                     | 302.903900      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 5800     | 256.699187   | 0.631207          |                     | 265.983093      |</pre>"
      ],
      "text/plain": [
       "| 3         | 5800     | 256.699187   | 0.631207          |                     | 265.983093      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 8800     | 267.086387   | 0.635341          |                     | 288.817108      |</pre>"
      ],
      "text/plain": [
       "| 3         | 8800     | 267.086387   | 0.635341          |                     | 288.817108      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 11800    | 277.447501   | 0.642373          |                     | 289.544220      |</pre>"
      ],
      "text/plain": [
       "| 3         | 11800    | 277.447501   | 0.642373          |                     | 289.544220      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 14800    | 287.937742   | 0.644189          |                     | 285.980103      |</pre>"
      ],
      "text/plain": [
       "| 3         | 14800    | 287.937742   | 0.644189          |                     | 285.980103      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 18000    | 298.191788   | 0.647833          |                     | 312.071960      |</pre>"
      ],
      "text/plain": [
       "| 3         | 18000    | 298.191788   | 0.647833          |                     | 312.071960      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 21300    | 308.220182   | 0.656338          |                     | 329.065643      |</pre>"
      ],
      "text/plain": [
       "| 3         | 21300    | 308.220182   | 0.656338          |                     | 329.065643      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 24700    | 318.368500   | 0.663846          |                     | 335.030640      |</pre>"
      ],
      "text/plain": [
       "| 3         | 24700    | 318.368500   | 0.663846          |                     | 335.030640      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 27800    | 328.369505   | 0.671475          |                     | 309.969086      |</pre>"
      ],
      "text/plain": [
       "| 3         | 27800    | 328.369505   | 0.671475          |                     | 309.969086      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 30600    | 338.752539   | 0.676895          |                     | 269.670929      |</pre>"
      ],
      "text/plain": [
       "| 3         | 30600    | 338.752539   | 0.676895          |                     | 269.670929      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 33600    | 349.111662   | 0.680298          |                     | 289.599640      |</pre>"
      ],
      "text/plain": [
       "| 3         | 33600    | 349.111662   | 0.680298          |                     | 289.599640      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 37000    | 359.403046   | 0.685838          |                     | 330.373291      |</pre>"
      ],
      "text/plain": [
       "| 3         | 37000    | 359.403046   | 0.685838          |                     | 330.373291      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 37300    | 362.253249   | 0.686273          | 0.817585            | 105.255264      |</pre>"
      ],
      "text/plain": [
       "| 3         | 37300    | 362.253249   | 0.686273          | 0.817585            | 105.255264      |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Checkpointing model into lenet 3</pre>"
      ],
      "text/plain": [
       "Checkpointing model into lenet 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+--------------+-------------------+---------------------+-----------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+--------------+-------------------+---------------------+-----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using network:\n",
      "\n",
      "### network layers ###\n",
      "layer[0]: ConvolutionLayer\n",
      "  init_random = xavier\n",
      "  padding = 1\n",
      "  stride = 2\n",
      "  num_channels = 32\n",
      "  num_groups = 1\n",
      "  kernel_size = 3\n",
      "layer[1]: MaxPoolingLayer\n",
      "  padding = 0\n",
      "  stride = 2\n",
      "  kernel_size = 3\n",
      "layer[2]: FlattenLayer\n",
      "layer[3]: DropoutLayer\n",
      "  threshold = 0.5\n",
      "layer[4]: FullConnectionLayer\n",
      "  init_sigma = 0.01\n",
      "  init_random = gaussian\n",
      "  init_bias = 0\n",
      "  num_hidden_units = 100\n",
      "layer[5]: SigmoidLayer\n",
      "layer[6]: FullConnectionLayer\n",
      "  init_sigma = 0.01\n",
      "  init_random = gaussian\n",
      "  init_bias = 0\n",
      "  num_hidden_units = 43\n",
      "layer[7]: SoftmaxLayer\n",
      "### end network layers ###\n",
      "\n",
      "### network parameters ###\n",
      "init_random = gaussian\n",
      "model_checkpoint_path = lenet 3\n",
      "learning_rate = 0.1\n",
      "input_shape = 1,28,28\n",
      "batch_size = 100\n",
      "divideby = 255\n",
      "model_checkpoint_interval = 1\n",
      "l2_regularization = 0.0\n",
      "momentum = 0.9\n",
      "### end network parameters ###\n",
      "\n",
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n"
     ]
    }
   ],
   "source": [
    ">>> trained_lenet = gl.neuralnet_classifier.create(ciresan_train, target='label',\n",
    "                                                   features= [ 'image'],\n",
    "...                                          network = lenet,\n",
    "...                                          #validation_set=validation_data,\n",
    "...                                          #metric=['accuracy', 'recall@2'],\n",
    "...                                          max_iterations=3,\n",
    "                                                   model_checkpoint_path ='lenet 3',\n",
    "                                              model_checkpoint_interval =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.739509105682373, 'confusion_matrix': Columns:\n",
       " \ttarget_label\tint\n",
       " \tpredicted_label\tint\n",
       " \tcount\tint\n",
       " \n",
       " Rows: 388\n",
       " \n",
       " Data:\n",
       " +--------------+-----------------+-------+\n",
       " | target_label | predicted_label | count |\n",
       " +--------------+-----------------+-------+\n",
       " |      0       |        1        |   40  |\n",
       " |      1       |        1        |  578  |\n",
       " |      2       |        1        |  103  |\n",
       " |      3       |        1        |   24  |\n",
       " |      4       |        1        |   62  |\n",
       " |      5       |        1        |   26  |\n",
       " |      7       |        1        |   4   |\n",
       " |      8       |        1        |   5   |\n",
       " |      14      |        1        |   1   |\n",
       " |      16      |        1        |   2   |\n",
       " +--------------+-----------------+-------+\n",
       " [388 rows x 3 columns]\n",
       " Note: Only the head of the SFrame is printed.\n",
       " You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_lenet.evaluate(ciresan_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import graphlab as gl\n",
    "alex_net = gl.deeplearning.get_builtin_neuralnet('imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bias_learning_rate': 0.02,\n",
       " 'init_random': 'gaussian',\n",
       " 'init_sigma': 0.01,\n",
       " 'input_shape': '3,227,227',\n",
       " 'l2_regularization': 0.0005,\n",
       " 'learning_rate': 0.01,\n",
       " 'learning_rate_gamma': 0.1,\n",
       " 'learning_rate_schedule': 'exponential_decay',\n",
       " 'learning_rate_step': 100000,\n",
       " 'momentum': 0.9,\n",
       " 'random_crop': 1,\n",
       " 'random_mirror': 1}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_net.params#verify(input_shape=(32,32,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "### network layers ###\n",
       "layer[0]: ConvolutionLayer\n",
       "  init_random = gaussian\n",
       "  padding = 0\n",
       "  stride = 4\n",
       "  num_channels = 96\n",
       "  num_groups = 1\n",
       "  kernel_size = 11\n",
       "layer[1]: RectifiedLinearLayer\n",
       "layer[2]: MaxPoolingLayer\n",
       "  padding = 0\n",
       "  stride = 2\n",
       "  kernel_size = 3\n",
       "layer[3]: LocalResponseNormalizationLayer\n",
       "  alpha = 0.001\n",
       "  beta = 0.75\n",
       "  knorm = 1\n",
       "  local_size = 5\n",
       "layer[4]: ConvolutionLayer\n",
       "  init_random = gaussian\n",
       "  padding = 2\n",
       "  stride = 1\n",
       "  num_channels = 256\n",
       "  num_groups = 2\n",
       "  kernel_size = 5\n",
       "layer[5]: RectifiedLinearLayer\n",
       "layer[6]: MaxPoolingLayer\n",
       "  padding = 0\n",
       "  stride = 2\n",
       "  kernel_size = 3\n",
       "layer[7]: LocalResponseNormalizationLayer\n",
       "  alpha = 0.001\n",
       "  beta = 0.75\n",
       "  knorm = 1\n",
       "  local_size = 5\n",
       "layer[8]: ConvolutionLayer\n",
       "  init_random = gaussian\n",
       "  padding = 1\n",
       "  stride = 1\n",
       "  num_channels = 384\n",
       "  num_groups = 1\n",
       "  kernel_size = 3\n",
       "layer[9]: RectifiedLinearLayer\n",
       "layer[10]: ConvolutionLayer\n",
       "  init_random = gaussian\n",
       "  padding = 1\n",
       "  stride = 1\n",
       "  num_channels = 384\n",
       "  num_groups = 2\n",
       "  kernel_size = 3\n",
       "layer[11]: RectifiedLinearLayer\n",
       "layer[12]: ConvolutionLayer\n",
       "  init_random = gaussian\n",
       "  padding = 1\n",
       "  stride = 1\n",
       "  init_bias = 1.0\n",
       "  num_channels = 256\n",
       "  num_groups = 2\n",
       "  kernel_size = 3\n",
       "layer[13]: RectifiedLinearLayer\n",
       "layer[14]: MaxPoolingLayer\n",
       "  padding = 0\n",
       "  stride = 2\n",
       "  kernel_size = 3\n",
       "layer[15]: FlattenLayer\n",
       "layer[16]: FullConnectionLayer\n",
       "  init_sigma = 0.005\n",
       "  init_random = gaussian\n",
       "  init_bias = 1.0\n",
       "  num_hidden_units = 4096\n",
       "layer[17]: RectifiedLinearLayer\n",
       "layer[18]: DropoutLayer\n",
       "  threshold = 0.5\n",
       "layer[19]: FullConnectionLayer\n",
       "  init_sigma = 0.005\n",
       "  init_random = gaussian\n",
       "  init_bias = 1.0\n",
       "  num_hidden_units = 4096\n",
       "layer[20]: RectifiedLinearLayer\n",
       "layer[21]: DropoutLayer\n",
       "  threshold = 0.5\n",
       "layer[22]: FullConnectionLayer\n",
       "  init_sigma = 0.01\n",
       "  init_random = gaussian\n",
       "  init_bias = 0\n",
       "  num_hidden_units = 1000\n",
       "layer[23]: SoftmaxLayer\n",
       "### end network layers ###\n",
       "\n",
       "### network parameters ###\n",
       "init_random = gaussian\n",
       "learning_rate = 0.01\n",
       "input_shape = 3,227,227\n",
       "learning_rate_gamma = 0.1\n",
       "learning_rate_schedule = exponential_decay\n",
       "random_mirror = 1\n",
       "learning_rate_step = 100000\n",
       "random_crop = 1\n",
       "init_sigma = 0.01\n",
       "bias_learning_rate = 0.02\n",
       "l2_regularization = 0.0005\n",
       "momentum = 0.9\n",
       "### end network parameters ###"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-f9b24f1010f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m                                          \u001b[0mmax_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                                                    \u001b[0mmodel_checkpoint_path\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'alexnet 3'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                                               model_checkpoint_interval =1)\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\admin\\AppData\\Local\\Dato\\Dato Launcher\\lib\\site-packages\\graphlab\\toolkits\\classifier\\neuralnet_classifier.pyc\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(dataset, target, features, max_iterations, network, validation_set, verbose, class_weights, **kwargs)\u001b[0m\n\u001b[0;32m    951\u001b[0m     \u001b[1;31m# use user specified network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m         \u001b[0m_network\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 953\u001b[1;33m         \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deeplearning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_input_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    954\u001b[0m         \u001b[0moutput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deeplearning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m         \u001b[1;31m# verify the netwo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\admin\\AppData\\Local\\Dato\\Dato Launcher\\lib\\site-packages\\graphlab\\toolkits\\deeplearning\\_main.pyc\u001b[0m in \u001b[0;36m_get_input_shape\u001b[1;34m(dataset, target, features)\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mdense_vec_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0m_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m             \u001b[0mret\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mret\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\admin\\AppData\\Local\\Dato\\Dato Launcher\\lib\\site-packages\\graphlab\\data_structures\\sarray.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   1049\u001b[0m             \u001b[0mub\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlb\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mblock_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[0mval_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSArray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_proxy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__proxy__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_range\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mub\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_cache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mub\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mval_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mother\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    ">>> trained_alex_net = gl.neuralnet_classifier.create(ciresan_train, target='label',\n",
    "                                                   features= [ 'image'],\n",
    "...                                          network = alex_net,\n",
    "...                                          #validation_set=validation_data,\n",
    "...                                          #metric=['accuracy', 'recall@2'],\n",
    "...                                          max_iterations=3,\n",
    "                                                   model_checkpoint_path ='alexnet 3',\n",
    "                                              model_checkpoint_interval =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionLayer\n",
       "  init_random = gaussian\n",
       "  padding = 0\n",
       "  stride = 1\n",
       "  num_channels = 200\n",
       "  num_groups = 1\n",
       "  kernel_size = 3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_net.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_net.layers[0].num_channels = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaxPoolingLayer\n",
       "  padding = 0\n",
       "  stride = 1\n",
       "  kernel_size = 3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_net.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_net.layers[1].kernel_size=2\n",
    "conv_net.layers[1].stride=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionLayer\n",
       "  init_random = gaussian\n",
       "  padding = 0\n",
       "  stride = 1\n",
       "  num_channels = 200\n",
       "  num_groups = 1\n",
       "  kernel_size = 3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_net.layers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_net.layers[2].num_channels=150\n",
    "conv_net.layers[2].kernel_size=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaxPoolingLayer\n",
       "  padding = 0\n",
       "  stride = 1\n",
       "  kernel_size = 3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_net.layers[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_net.layers[3].kernel_size=2\n",
    "conv_net.layers[3].stride=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionLayer\n",
       "  init_random = gaussian\n",
       "  padding = 0\n",
       "  stride = 1\n",
       "  num_channels = 200\n",
       "  num_groups = 1\n",
       "  kernel_size = 3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_net.layers[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_net.layers[4].num_channels=250\n",
    "conv_net.layers[4].kernel_size=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaxPoolingLayer\n",
       "  padding = 0\n",
       "  stride = 1\n",
       "  kernel_size = 3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_net.layers[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_net.layers[5].kernel_size=2\n",
    "conv_net.layers[5].stride=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "layer[0]: ConvolutionLayer\n",
       "  init_random = gaussian\n",
       "  padding = 0\n",
       "  stride = 1\n",
       "  num_channels = 100\n",
       "  num_groups = 1\n",
       "  kernel_size = 3\n",
       "layer[1]: MaxPoolingLayer\n",
       "  padding = 0\n",
       "  stride = 2\n",
       "  kernel_size = 2\n",
       "layer[2]: ConvolutionLayer\n",
       "  init_random = gaussian\n",
       "  padding = 0\n",
       "  stride = 1\n",
       "  num_channels = 150\n",
       "  num_groups = 1\n",
       "  kernel_size = 4\n",
       "layer[3]: MaxPoolingLayer\n",
       "  padding = 0\n",
       "  stride = 2\n",
       "  kernel_size = 2\n",
       "layer[4]: ConvolutionLayer\n",
       "  init_random = gaussian\n",
       "  padding = 0\n",
       "  stride = 1\n",
       "  num_channels = 250\n",
       "  num_groups = 1\n",
       "  kernel_size = 3\n",
       "layer[5]: MaxPoolingLayer\n",
       "  padding = 0\n",
       "  stride = 2\n",
       "  kernel_size = 2\n",
       "layer[6]: FlattenLayer"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_net.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ">>> percpt_net = gl.deeplearning.MultiLayerPerceptrons(num_hidden_layers=2,\n",
    "                                                num_hidden_units=[200,43])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ">>> conv_net.layers.extend(percpt_net.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "### network layers ###\n",
       "layer[0]: ConvolutionLayer\n",
       "  init_random = gaussian\n",
       "  padding = 0\n",
       "  stride = 1\n",
       "  num_channels = 100\n",
       "  num_groups = 1\n",
       "  kernel_size = 3\n",
       "layer[1]: MaxPoolingLayer\n",
       "  padding = 0\n",
       "  stride = 1\n",
       "  kernel_size = 3\n",
       "layer[2]: ConvolutionLayer\n",
       "  init_random = gaussian\n",
       "  padding = 0\n",
       "  stride = 1\n",
       "  num_channels = 200\n",
       "  num_groups = 1\n",
       "  kernel_size = 3\n",
       "layer[3]: MaxPoolingLayer\n",
       "  padding = 0\n",
       "  stride = 1\n",
       "  kernel_size = 3\n",
       "layer[4]: ConvolutionLayer\n",
       "  init_random = gaussian\n",
       "  padding = 0\n",
       "  stride = 1\n",
       "  num_channels = 200\n",
       "  num_groups = 1\n",
       "  kernel_size = 3\n",
       "layer[5]: MaxPoolingLayer\n",
       "  padding = 0\n",
       "  stride = 1\n",
       "  kernel_size = 3\n",
       "layer[6]: FlattenLayer\n",
       "layer[7]: FullConnectionLayer\n",
       "  init_sigma = 0.01\n",
       "  init_random = gaussian\n",
       "  init_bias = 0\n",
       "  num_hidden_units = 200\n",
       "layer[8]: SigmoidLayer\n",
       "layer[9]: FullConnectionLayer\n",
       "  init_sigma = 0.01\n",
       "  init_random = gaussian\n",
       "  init_bias = 0\n",
       "  num_hidden_units = 43\n",
       "layer[10]: SoftmaxLayer\n",
       "### end network layers ###\n",
       "\n",
       "### network parameters ###\n",
       "learning_rate = 0.001\n",
       "momentum = 0.9\n",
       "### end network parameters ###"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.001, 'momentum': 0.9}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_net.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dato_net_1000 = gl.load_model('Dato net- 1000 - bien bao giao thong/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "### network layers ###\n",
       "layer[0]: ConvolutionLayer\n",
       "  init_random = gaussian\n",
       "  padding = 0\n",
       "  stride = 2\n",
       "  num_channels = 10\n",
       "  num_groups = 1\n",
       "  kernel_size = 3\n",
       "layer[1]: MaxPoolingLayer\n",
       "  padding = 0\n",
       "  stride = 2\n",
       "  kernel_size = 3\n",
       "layer[2]: FlattenLayer\n",
       "layer[3]: FullConnectionLayer\n",
       "  init_sigma = 0.01\n",
       "  init_random = gaussian\n",
       "  init_bias = 0\n",
       "  num_hidden_units = 100\n",
       "layer[4]: RectifiedLinearLayer\n",
       "layer[5]: DropoutLayer\n",
       "  threshold = 0.5\n",
       "layer[6]: FullConnectionLayer\n",
       "  init_sigma = 0.01\n",
       "  init_random = gaussian\n",
       "  init_bias = 0\n",
       "  num_hidden_units = 43\n",
       "layer[7]: SoftmaxLayer\n",
       "### end network layers ###\n",
       "\n",
       "### network parameters ###\n",
       "learning_rate = 0.001\n",
       "metric = accuracy,recall@2\n",
       "momentum = 0.9\n",
       "### end network parameters ###"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dato_net_1000.network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1,30,30'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dato_net_1000.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9084718823432922, 'confusion_matrix': Columns:\n",
       " \ttarget_label\tint\n",
       " \tpredicted_label\tint\n",
       " \tcount\tint\n",
       " \n",
       " Rows: 349\n",
       " \n",
       " Data:\n",
       " +--------------+-----------------+-------+\n",
       " | target_label | predicted_label | count |\n",
       " +--------------+-----------------+-------+\n",
       " |      0       |        0        |   27  |\n",
       " |      0       |        1        |   13  |\n",
       " |      1       |        1        |  659  |\n",
       " |      2       |        1        |   18  |\n",
       " |      3       |        1        |   2   |\n",
       " |      4       |        1        |   9   |\n",
       " |      5       |        1        |   5   |\n",
       " |      7       |        1        |   3   |\n",
       " |      10      |        1        |   2   |\n",
       " |      11      |        1        |   1   |\n",
       " +--------------+-----------------+-------+\n",
       " [349 rows x 3 columns]\n",
       " Note: Only the head of the SFrame is printed.\n",
       " You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dato_net_1000.evaluate(ciresan_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">path</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">image</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 227 Width: 227</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 227 Width: 227</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 227 Width: 227</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 227 Width: 227</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 227 Width: 227</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 227 Width: 227</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 227 Width: 227</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 227 Width: 227</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 227 Width: 227</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E:/COGNITIVE_SCIENCE/ARTI<br>FICIAL_INTELLIGENCE/R ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 227 Width: 227</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">26</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[39209 rows x 3 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tpath\tstr\n",
       "\timage\tImage\n",
       "\tlabel\tint\n",
       "\n",
       "Rows: 39209\n",
       "\n",
       "Data:\n",
       "+-------------------------------+------------------------+-------+\n",
       "|              path             |         image          | label |\n",
       "+-------------------------------+------------------------+-------+\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 227 Width: 227 |   18  |\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 227 Width: 227 |   8   |\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 227 Width: 227 |   24  |\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 227 Width: 227 |   15  |\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 227 Width: 227 |   9   |\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 227 Width: 227 |   5   |\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 227 Width: 227 |   38  |\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 227 Width: 227 |   6   |\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 227 Width: 227 |   10  |\n",
       "| E:/COGNITIVE_SCIENCE/ARTIF... | Height: 227 Width: 227 |   26  |\n",
       "+-------------------------------+------------------------+-------+\n",
       "[39209 rows x 3 columns]\n",
       "Note: Only the head of the SFrame is printed.\n",
       "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ciresan_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "layer[0]: ConvolutionLayer\n",
       "  init_random = gaussian\n",
       "  padding = 0\n",
       "  stride = 1\n",
       "  num_channels = 100\n",
       "  num_groups = 1\n",
       "  kernel_size = 3\n",
       "layer[1]: RectifiedLinearLayer\n",
       "layer[2]: MaxPoolingLayer\n",
       "  padding = 0\n",
       "  stride = 2\n",
       "  kernel_size = 2\n",
       "layer[3]: ConvolutionLayer\n",
       "  init_random = gaussian\n",
       "  padding = 0\n",
       "  stride = 1\n",
       "  num_channels = 150\n",
       "  num_groups = 1\n",
       "  kernel_size = 4\n",
       "layer[4]: RectifiedLinearLayer\n",
       "layer[5]: MaxPoolingLayer\n",
       "  padding = 0\n",
       "  stride = 2\n",
       "  kernel_size = 2\n",
       "layer[6]: ConvolutionLayer\n",
       "  init_random = gaussian\n",
       "  padding = 0\n",
       "  stride = 1\n",
       "  num_channels = 250\n",
       "  num_groups = 1\n",
       "  kernel_size = 3\n",
       "layer[7]: RectifiedLinearLayer\n",
       "layer[8]: MaxPoolingLayer\n",
       "  padding = 0\n",
       "  stride = 2\n",
       "  kernel_size = 2\n",
       "layer[9]: FlattenLayer\n",
       "layer[10]: FullConnectionLayer\n",
       "  init_sigma = 0.01\n",
       "  init_random = gaussian\n",
       "  init_bias = 0\n",
       "  num_hidden_units = 200\n",
       "layer[11]: RectifiedLinearLayer\n",
       "layer[12]: FullConnectionLayer\n",
       "  init_sigma = 0.01\n",
       "  init_random = gaussian\n",
       "  init_bias = 0\n",
       "  num_hidden_units = 43\n",
       "layer[13]: RectifiedLinearLayer\n",
       "layer[14]: SoftmaxLayer"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_net.layers.insert(13, gl.deeplearning.layers.RectifiedLinearLayer())\n",
    ">>> conv_net.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "layer[0]: ConvolutionLayer\n",
       "  init_random = gaussian\n",
       "  padding = 0\n",
       "  stride = 1\n",
       "  num_channels = 100\n",
       "  num_groups = 1\n",
       "  kernel_size = 3\n",
       "layer[1]: RectifiedLinearLayer\n",
       "layer[2]: MaxPoolingLayer\n",
       "  padding = 0\n",
       "  stride = 2\n",
       "  kernel_size = 2\n",
       "layer[3]: ConvolutionLayer\n",
       "  init_random = gaussian\n",
       "  padding = 0\n",
       "  stride = 1\n",
       "  num_channels = 150\n",
       "  num_groups = 1\n",
       "  kernel_size = 4\n",
       "layer[4]: RectifiedLinearLayer\n",
       "layer[5]: MaxPoolingLayer\n",
       "  padding = 0\n",
       "  stride = 2\n",
       "  kernel_size = 2\n",
       "layer[6]: ConvolutionLayer\n",
       "  init_random = gaussian\n",
       "  padding = 0\n",
       "  stride = 1\n",
       "  num_channels = 250\n",
       "  num_groups = 1\n",
       "  kernel_size = 3\n",
       "layer[7]: RectifiedLinearLayer\n",
       "layer[8]: MaxPoolingLayer\n",
       "  padding = 0\n",
       "  stride = 2\n",
       "  kernel_size = 2\n",
       "layer[9]: FlattenLayer\n",
       "layer[10]: FullConnectionLayer\n",
       "  init_sigma = 0.01\n",
       "  init_random = gaussian\n",
       "  init_bias = 0\n",
       "  num_hidden_units = 200\n",
       "layer[11]: RectifiedLinearLayer\n",
       "layer[12]: FullConnectionLayer\n",
       "  init_sigma = 0.01\n",
       "  init_random = gaussian\n",
       "  init_bias = 0\n",
       "  num_hidden_units = 43\n",
       "layer[13]: SoftmaxLayer"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del conv_net.layers[13]\n",
    "conv_net.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print conv_net.verify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lưu lại mạng IDSIA net:\n",
    "Chưa chạy nên nó mới chỉ là cái khung xương (net architecture). Chạy rồi mới đắp thịt (trọng số) lên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_net.save('ciresan neural net for traffic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load nó:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import graphlab as gl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idsia_net.params['learning_rate']=idsia_net.params['learning_rate']*100\n",
    "idsia_net.params['learning_rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đây là kết quả của mạng Dato! Vẫn chưa chạy được mạng do chính mình thiết kế, dù là bắt chước người khác"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8864607810974121, 'confusion_matrix': Columns:\n",
       " \ttarget_label\tint\n",
       " \tpredicted_label\tint\n",
       " \tcount\tint\n",
       " \n",
       " Rows: 322\n",
       " \n",
       " Data:\n",
       " +--------------+-----------------+-------+\n",
       " | target_label | predicted_label | count |\n",
       " +--------------+-----------------+-------+\n",
       " |      0       |        0        |   17  |\n",
       " |      11      |        0        |   1   |\n",
       " |      0       |        1        |   17  |\n",
       " |      1       |        1        |  652  |\n",
       " |      2       |        1        |   34  |\n",
       " |      3       |        1        |   2   |\n",
       " |      4       |        1        |   21  |\n",
       " |      5       |        1        |   3   |\n",
       " |      7       |        1        |   1   |\n",
       " |      8       |        1        |   1   |\n",
       " +--------------+-----------------+-------+\n",
       " [322 rows x 3 columns]\n",
       " Note: Only the head of the SFrame is printed.\n",
       " You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_cnn.evaluate(ciresan_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
